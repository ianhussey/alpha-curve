---
title: "Data extraction"
output: html_document
---

# Notes

Because this script has to load a very large number of files (75k), run time is slow. This mostly depends on your HDD read/write speed, could be 45 mins with an M2 SSD or 4 hours with a slower one.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Dependencies

```{r}

library(tidyverse)
library(stringr)
library(httr)

```

# Delete existing csv files

For dev, if you want to clear the existing csv files.

```{r eval=FALSE, include=TRUE}

csv_files_to_delete <- 
  list.files(path = "../../data/apa_articles", 
             pattern = ".csv", 
             recursive = TRUE, 
             full.names = TRUE)

for(csv in csv_files_to_delete){
 unlink(csv)
}

```

# Examine contents of all folders

```{r}

files <- 
  list.files(path = "../../data/apa_articles", 
             recursive = TRUE)

files_df <- 
  tibble(dir_and_file = files) |>
  separate(dir_and_file, into = c("dir", "file"), sep = "/") |>
  count(file)

files_df

```

# Extract strings from articles

Input: Assumes a folder called `apa_articles` exists, and inside it are folders named with doi numbers. Inside each folder is a file called `fulltext.txt` which contains the article text.
Output: Creates a file called `results.csv` in each folder containing the results for that article.

NB this script could take a really long time. It can be stopped and restarted and will skip files that already have a `results.csv` in the folder. 

```{r}

# Get a list of articles to go through
dois <- list.files('../../data/apa_articles/') 

# Extract the results from each paper
for(doi in dois) {
  
  try(
    
    if(!file.exists(sprintf('../../data/apa_articles/%s/results.csv', doi))) {  
      
      filename <- sprintf('../../data/apa_articles/%s/fulltext.txt', doi)  
      
      txt <- readChar(filename, file.info(filename)$size)
      
      txt <- gsub(pattern = '_', replacement = '', x = txt)
      txt <- gsub(pattern = '&lt;', replacement = '<', x = txt)
      txt <- gsub(pattern = '&gt;', replacement = '>', x = txt)
      
      total_length <- nchar(txt)
      
      # search for 'cronbach' with text
      locations_cronbach <- 
        str_locate_all(pattern = "(C|c)ronbach('|’)?s? (alpha|a|α)", txt)[[1]]

      pre_cronbach <- 
        str_sub(txt,
                start = locations_cronbach[, 2] - 60,
                end = locations_cronbach[, 2])
      
      post_cronbach <- 
        str_sub(txt,
                start = locations_cronbach[, 2],
                end = locations_cronbach[, 2] + 50)
      
      # combine results into long data frames
      data_total_length <- 
        data.frame(total_length = total_length) %>%
        rownames_to_column(var = "exemplar") %>%
        gather(key, value, -exemplar) %>%
        mutate(type = "length",
               doi = doi,
               value = as.character(value))

      string_cronbach <- 
        data.frame(locations_cronbach = locations_cronbach,
                   pre_cronbach = pre_cronbach,
                   post_cronbach = post_cronbach) %>%
        rownames_to_column(var = "exemplar") %>%
        gather(key, value, -exemplar) %>%
        mutate(type = "string_cronbach",
               doi = doi)
      
      # combine dfs
      df <- 
        bind_rows(data_total_length,
                  string_cronbach) %>%
        dplyr::select(doi, exemplar, type, key, value)
      
      # write to disk
      write.csv(df, 
                sprintf('../../data/apa_articles/%s/results.csv', doi),
                row.names = FALSE)

      # print names of completed files
      cat(sprintf('%s\n', doi)) 
    },
    silent = TRUE
  )
}

```

# Combine csv files & write to disk

```{r}

results_files_names <- 
  list.files(path = "../../data/apa_articles", 
             pattern = ".csv", 
             recursive = TRUE, 
             full.names = TRUE)

data_combined_results_files <- 
  results_files_names |>
  map_dfr(~ read_csv(.x, show_col_types = FALSE) |> 
            mutate(across(everything(), as.character)), 
          show_col_types = FALSE) |>
  filter(key %in% c("pre_cronbach", "post_cronbach", "total_length"))

dir.create("../../data/processed")

# write_rds(data_combined_results_files,
#           "../../data/processed/data_combined_results_files.rds")

write_csv(data_combined_results_files,
          "../../data/processed/data_combined_results_files.csv")

```

# Session info

```{r}

sessionInfo()

```
