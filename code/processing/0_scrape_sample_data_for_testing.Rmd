
Assumes that "example articles for testing" directory contains folders each of which contain a single pdf of an academic article.

```{r}

library(pdftools)
library(tidyverse)
library(jsonlite)
library(lubridate)

```

# folders should have only pdfs in them

```{r}

# delete all .txt files
txt_files_to_delete <-
  list.files(path = "../../data/example articles for testing",
             pattern = ".txt",
             recursive = TRUE,
             full.names = TRUE)

for(i in 1:length(txt_files_to_delete)){
 unlink(txt_files_to_delete[i])
}

# delete all .csv files
csv_files_to_delete <-
  list.files(path = "../../data/example articles for testing",
             pattern = ".csv",
             recursive = TRUE,
             full.names = TRUE)

for(i in 1:length(csv_files_to_delete)){
 unlink(csv_files_to_delete[i])
}

# # delete all .png files
# png_files_to_delete <-
#   list.files(path = "../../data/example articles for testing",
#              pattern = ".png",
#              recursive = TRUE,
#              full.names = TRUE)
# 
# for(i in 1:length(png_files_to_delete)){
#  unlink(png_files_to_delete[i])
# }

# delete non pdf files - unreliable, needs other functions targetting specific files
files_to_delete <- 
  grep(list.files(path = "../../data/example articles for testing",
                  recursive = TRUE,
                  full.names = TRUE,
                  all.files = TRUE), 
       pattern = ".pdf", 
       invert = TRUE, 
       value = TRUE)

for(i in files_to_delete){
 file.remove(i)
}

# # delete all hidden zotero files
# zot_files_to_delete <- 
#   list.files(path = "../../data/example articles for testing", 
#              pattern = ".zotero", 
#              invert = TRUE,
#              recursive = TRUE, 
#              full.names = TRUE,
#              all.files = TRUE)
# 
# for(i in 1:length(zot_files_to_delete)){
#  file.remove(zot_files_to_delete[i])
# }

# delete empty directories
folders <- list.files(path = "../../data/example articles for testing", full.names = TRUE)

for(i in folders){
 icesTAF::rmdir(i, recursive = TRUE)
}

```

# scrape pdf text

```{r}

# create vector of all PDF paths and names 
files <- 
  list.files(path = "../../data/example articles for testing", 
             pattern = ".pdf", 
             recursive = TRUE, 
             full.names = TRUE)

# create vector of all folder names that contain the pdfs (assumes no empty folders)
folders <- 
  str_split(str_remove(files, "../../data/example articles for testing/"),
            "/", simplify = TRUE)[,1]
            

for(i in 1:length(files)) {
  if(!file.exists(sprintf('../../data/example articles for testing/%s/fulltext.txt', folders[i]))) { 
    try(
      pdftools::pdf_text(pdf = files[i]) |>
        paste(collapse = " ") |>
        gsub(pattern = "\\s+", replacement = " ") |>
        write_file(sprintf('../../data/example articles for testing/%s/fulltext.txt', folders[i])),
      silent = TRUE
    )
  } 
}
  
```
  
- then manually rename "example articles for testing" directory to "apa_articles" to use data processing scripts on this testing data.


