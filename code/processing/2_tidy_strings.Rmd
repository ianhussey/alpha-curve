---
title: "Data extraction"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- string parsing only covers the first instance in the string. should i extract subsequent ones? likely higher coverage but lower specificity.
- remove "needed" or "cutoff"
- examples to exclude: 
  - repeat appearances in string aren't captured: "ranges from 0.75 to 0.89" returns "0.75"
  - "a = .90–.95" returns ".90". should i exclude on the basis of range if its followed by a dash?

# Overview

The previous script, "1_extract_strings.Rmd" finds instances of (variants of) "Cronbach's alpha" and saves the 50 characters after this matches to a csv file. This extraction is quite slow as it has to iterate over larger txt files. This file does the second stage of data processing, by extracting Cronbach's alpha estimates from these 50 character strings and excluding instances that are less likely to be valid alpha estimates.

As in "1_extract_strings.Rmd", the goal here is to prioritize specificity over sensitivity. Likely many alpha estimates will not be extracted (e.g., those in tables), but we want high confidence that the values that are extracted are valid Cronbach's alpha estimates.   

```{r setup, include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

```

# Dependencies

```{r}

library(tidyverse)

```

# Regex tests

Test some of the regex that is used below. NB leading spaces in strings don't print correctly.

```{r}

regex_tests <- 
  tibble(string = c("in the current sample was 0.7", "= 0.7", "= .7", "=.7", " 0.7", " .7", "section 2.7", "doi 0.0.7"),
         required_result = c(.7, .7, .7, .7, .7, .7, NA, NA)) |>
  mutate(result = as.numeric(str_extract(required_result, "([0]|\\s|=)\\.[0-9]")),
         test_passed = ifelse(result == required_result | (is.na(result) & is.na(required_result)), TRUE, FALSE))

regex_tests

```

# Extract Cronbach's alphas from extracted strings

```{r}

results_files_names <- 
  list.files(path = "../../data/apa_articles", 
             pattern = ".csv", 
             recursive = TRUE, 
             full.names = TRUE)

data_combined_results_files <- 
  results_files_names |>
  map_dfr(~ read_csv(.x, show_col_types = FALSE) |> 
            mutate(across(everything(), as.character)), 
          show_col_types = FALSE) |>
  filter(key %in% c("post_cronbach", "total_length"))

data_article_length <- data_combined_results_files |>
  filter(key == "total_length") |>
  select(doi, total_length_of_article = value)

data_processed <- data_combined_results_files |>
  # check that there are not strings between "cronbach" and the estimate that suggest this is something other than a cronbach's alpha estimate 
  # e.g, reporting of a cutoff value ("cronbach's alpha of > .70"; this could get rid of real values too but more important that we exclude rules of thumb being reported)
  # e.g., a p value ("p < .05"). several of these were found.
  mutate(alpha_locate = str_locate(value, "([0]|\\s|=)\\.[0-9]*")[,"start"],
         substring = str_sub(value, start = 1, end = alpha_locate),
         comparison_present = str_detect(substring, "([<>≥≤]|exceeding|lower|above|below|greater than|less than|more than|between)"),
         comparison_present_after_estimate = str_detect(value, "(or above|or more|or greater|or below|or less|or lower)"),
         cutoff_present = str_detect(substring, "cut(\\s|-)off"),
         range_present = str_detect(substring, "(range|ranging|between|from)"),
         p_present = str_detect(substring, "p\\s*[=<>≥≤]"),
         doi_present = str_detect(tolower(substring), "(doi:|doi.org)"),
         # something about references to this journal keep getting confused for alpha values
         psychometrika_present = str_detect(tolower(substring), "psychometrika")) |>
  # extract the estimate
  mutate(alpha = str_extract(value, "([0]|\\s|=)\\.[0-9]*"),
         alpha = str_remove(alpha, "="),
         alpha = ifelse(alpha == "." |
                          comparison_present == TRUE |
                          comparison_present_after_estimate == TRUE |
                          cutoff_present == TRUE |
                          range_present == TRUE |
                          p_present == TRUE |
                          doi_present == TRUE |
                          psychometrika_present == TRUE, 
                        NA, 
                        as.numeric(alpha))) |>
  select(doi, exemplar, text = value, alpha) |>
  full_join(data_article_length, by = "doi") |>
  mutate(text = ifelse(text == total_length_of_article, NA, text)) |>
  # drop duplicate combinations of doi and exemplar
  distinct(doi, exemplar, .keep_all = TRUE)

data_processed_trimmed <- data_processed |>
  drop_na()
  
```

# Write to disk

```{r}

dir.create("../../data/processed")

write_csv(data_processed_trimmed, "../../data/processed/data_processed_trimmed.csv")
write_csv(data_processed, "../../data/processed/data_processed.csv")

```

# Session info

```{r}

sessionInfo()

```
