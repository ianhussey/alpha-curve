---
title: "An excess of Cronbach's α values at rule-of-thumb cut-offs"
subtitle: "Analyses of psycTests dataset"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

```

# Dependencies

```{r}

library(tidyverse)
library(scales)
library(ggtext)
library(broom)
library(extraDistr)
library(patchwork)
library(coin)
library(knitr)
library(kableExtra)
library(janitor)

dir.create("plots")

# disable scientific notation
options(scipen=999)

# set seed
set.seed(42)

```

# Get data

```{r}

data_processed <- read_rds("../../data/processed/psycTests/data_processed_psyctests.rds")

data_processed_binned <- data_processed %>%
  # round the alpha values to 2 decimal places, using standard rounding method
  # recode alpha values of 0 or 1 to .01 or .99, in order to be able to fit beta regression
  # nb none present in dataset
  mutate(alpha = janitor::round_half_up(alpha, 2),
         alpha = case_when(alpha == 0 ~ 0.01,
                           alpha == 1 ~ 0.99,
                           TRUE ~ alpha)) 

```

# Descriptives

## Full sample

```{r}

data_psyctests <- read_rds("../../data/raw/psycTests/preprocessed_records.rds")

n_doi <- data_psyctests |>
  distinct(DOI) |>
  nrow()

cat("n articles =", n_doi, "\n")

```

```{r}

n_scale_names <- data_psyctests %>%
  distinct(Name) |>
  arrange(Name) |>
  nrow()

cat("n scale names =", n_scale_names, "\n")


# data_psyctests_cleaned_names <- data_psyctests %>%
#   mutate(
#     Name = tolower(Name),
#     Name = str_replace_all(Name, "--.*", ""), # translations are often be append with "-- spanish version" etc
#     Name = str_replace_all(Name, ";.*", ""),  # translations are sometimes append with "; spanish version" etc
#     Name = str_remove_all(Name, "-( )revised"), # drop revised scales for a conservative estimate
#     Name = str_replace_all(Name, "scales", "scale"), # scales vs scale may be the same scale
#     Name = str_replace_all(Name, "-[0-9]+.*", ""), # number of items is often appended as "-12" etc
#     Name = str_replace_all(Name, "\\b\\d+\\s?-\\s?item\\s?", ""), # drops "N-item" as these may be versions of the same original scale
#     Name = str_replace_all(Name, "( |-)\\S+ version", "") # drops things like "-russian version" and "-child version" and " mother version"
#   ) |>
#   distinct(Name) |>
#   arrange(Name)

data_psyctests_cleaned_names <- data_psyctests %>%
  mutate(
    Name_base = tolower(Name_base),
    Name_base = str_replace_all(Name_base, "--.*", ""), # translations are often be append with "-- spanish version" etc
    Name_base = str_replace_all(Name_base, ";.*", ""),  # translations are sometimes append with "; spanish version" etc
    Name_base = str_remove_all(Name_base, "-( )revised"), # drop revised scales for a conservative estimate
    Name_base = str_replace_all(Name_base, "scales", "scale"), # scales vs scale may be the same scale
    Name_base = str_replace_all(Name_base, "-[0-9]+.*", ""), # number of items is often appended as "-12" etc
    Name_base = str_replace_all(Name_base, "\\b\\d+\\s?-\\s?item\\s?", ""), # drops "N-item" as these may be versions of the same original scale
    Name_base = str_replace_all(Name_base, "( |-)\\S+ version", "") # drops things like "-russian version" and "-child version" and " mother version"
  ) |>
  distinct(Name_base) |>
  arrange(Name_base)

n_unique_scale_names <- data_psyctests_cleaned_names |>
  nrow()

cat("n unique scale names after removing apparent duplicates, translations and versions =", n_unique_scale_names, "\n")

```

```{r}

data_psyctests %>%
  summarize(earliest_year = min(TestYear, na.rm = TRUE),
            latest_year = max(TestYear, na.rm = TRUE))

data_psyctests |>
  select(DOI, TestYear, Name) |>
  arrange(TestYear) |>
  slice(1:10)

```

```{r}

data_journals <- data_psyctests |>
  select(DOI, SourceCitationList) %>%
  rowwise(DOI) |>
  mutate(data = list(as.data.frame(unlist(SourceCitationList)))) |>
  unnest(data) |>
  ungroup() |>
  rename(text = `unlist(SourceCitationList)`) |>
  group_by(DOI) |>
  mutate(var = row_number()) |>
  ungroup() |>
  pivot_wider(names_from = var,
              names_prefix = "X",
              values_from = text) |>
  select(DOI, journal = X2) |>
  mutate(journal = tolower(journal),
         journal = str_replace_all(journal, ", vol\\. \\d+\\.?", ""),
         journal = str_remove_all(journal, "  "),
         journal = str_remove_all(journal, "\n")) |>
  distinct(journal) |>
  arrange(journal) |>
  filter(!str_detect(journal, "adaptation") & # drop non journals: scale adaptations
           !str_detect(journal, "\\d{4}-\\d{4}-\\d{4}-\\d{3}") &
           !str_detect(journal, "study") &
           !str_detect(journal, "instrument") &
           !str_detect(journal, "conference") &
           !str_detect(journal, "survey") &
           !str_detect(journal, "measure ") &
           !str_detect(journal, "revised ") &
           !str_detect(journal, "tool ") &
           !str_detect(journal, "tests ") &
           !str_detect(journal, "revised ") &
           !str_detect(journal, "symptom ") &
           !str_detect(journal, "short ") &
           !str_detect(journal, "short-form") &
           !str_detect(journal, "questionnaire") &
           !str_detect(journal, "scale") &
           !str_detect(journal, "reliabil") &
           !str_detect(journal, "valid") &
           !str_detect(journal, "academic self-efficacy in education: nature, assessment, and research") &
           !str_detect(journal, "adapting ") &
           !str_detect(journal, "guide ") &
           !str_detect(journal, "index ") &
           !str_detect(journal, " test") &
           !str_detect(journal, "inventory ") &
           !str_detect(journal, "assessing ") &
           !str_detect(journal, "analysis of") &
           !str_detect(journal, "analyses of") &
           !str_detect(journal, " model") &
           !str_detect(journal, "assessment of") &
           !str_detect(journal, "an assessment") &
           !str_detect(journal, "factor structure") &
           !str_detect(journal, "factor analy") &
           !str_detect(journal, "psychometric ") &
           !str_detect(journal, "a new method for analyzing early mother-child interactions") &
           !str_detect(journal, "raising awareness among secondary school students about the needsof their deaf and hard-of-hearing peers") &
           !str_detect(journal, "rape prevention through bystander education: bringing abroader community perspective to sexual violence prevention"))

write_csv(data_journals, "../../data/processed/psycTests/data_psyctests_journals.csv")

n_journals <- data_journals |>
  nrow()

cat("n journals =", n_journals, "\n")

```

```{r}

n_estimates_after_exclusions <- data_processed |>
  nrow() 

cat("n alpha estimates after exclusions =", n_estimates_after_exclusions, "\n")

doi_with_at_least_one_alpha <- data_processed |>
  select(doi, alpha) |>
  group_by(doi) |>
  summarize(at_least_one_alpha = max(!is.na(alpha))) |>
  summarize(doi_with_at_least_one_alpha = janitor::round_half_up(mean(at_least_one_alpha)*100, 1)) |>
  pull(doi_with_at_least_one_alpha)

cat("% dois with at least one alpha =", doi_with_at_least_one_alpha, "%\n")

```

## By test type

```{r}

n_doi_by_test_type <- data_psyctests |>
  distinct(DOI, test_type) |>
  count(test_type, name = "n_dois")

n_estimates_after_exclusions_by_test_type <- data_processed |>
  count(test_type, name = "n_estimates")

n_by_test_type <- 
  full_join(n_doi_by_test_type,
            n_estimates_after_exclusions_by_test_type, 
            by = "test_type") |>
  mutate(mean_estimates_per_doi = janitor::round_half_up(n_estimates / n_dois, digits = 1)) |>
  arrange(desc(n_dois))

n_by_test_type |>
  kable() |>
  kable_classic(full_width = FALSE)
  
```

# All tests (full sample)

## Kernel smoothing

### Model and plot

```{r}

data_included <- data_processed %>% 
  mutate(alpha = alpha_all) |>
  filter(exclude_master == FALSE) 

nrow(data_included)

# create tibble containing all alpha bins, for a later join
all_alphas <- tibble(alpha = as.character(seq(0.01, 0.99, 0.01)),
                     freq = 0,
                     missing = TRUE)

data_processed_binned <- data_included %>% 
  pull(alpha) %>% 
  unlist() %>% 
  as.numeric() %>% 
  tibble(alpha = .) %>% 
  filter(alpha > 0, !is.na(alpha)) %>% 
  mutate(alpha = janitor::round_half_up(alpha, 2),
         alpha = case_when(alpha == 0 ~ 0.01,
                           alpha == 1 ~ 0.99,
                           TRUE ~ alpha))

data_frequency_temp <- data_processed_binned %>% 
  mutate(n_total = n()) %>% 
  group_by(alpha) %>% 
  summarise(freq = sum(!is.na(alpha))/first(n_total)) %>%
  # convert alpha to character to facilitate a join later
  mutate(alpha = as.character(alpha))

# kernel density estimation
data_density <- 
  density(data_processed_binned %>%
            pull(alpha),
          n      = length(seq(0.01, 0.99, 0.01)),
          from   = 0.01,
          to     = 0.99, 
          kernel = "gaussian",
          bw     = 0.01) # "nrd0" returns 0.01

data_frequency <- data_frequency_temp %>%
  # join the previous two tibbles to create a complete list of alpha bins
  bind_rows(all_alphas %>% anti_join(data_frequency_temp, by = "alpha")) %>%
  arrange(alpha, desc(freq)) %>%
  distinct(alpha, .keep_all = TRUE) %>%
  mutate(density_kernel = data_density$y,
         missing = ifelse(is.na(missing), FALSE, missing)) %>%
  mutate(residual_kernel = freq*100 - density_kernel,
         alpha = as.numeric(alpha),
         missing = ifelse(is.na(missing), FALSE, missing))

total_n <- nrow(data_processed_binned)/100

plot_data_psyctests <- data_processed_binned |>
  mutate(n_total = n()) |>
  group_by(alpha) |>
  summarise(count = sum(!is.na(alpha))) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Common reliability threshold",
                          TRUE ~ "Non-threshold"),
         type = fct_relevel(type, "Non-threshold", "Common reliability threshold")) |>
  right_join(data_frequency, by = "alpha") |>
  mutate(excess = if_else(residual_kernel > 0, "excess", "deficit"))# %>% 
# drop_na()

c_excess <- "#2A788EFF"
c_data <- "lightgrey"
c_line <- "black"
c_lpbg <- "white"
c_grid <- "#F0F0F0AA"

p1_kernel_psyctests <-
  ggplot(plot_data_psyctests, aes(alpha, y = count, fill = excess)) +
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col() +
  geom_col(aes(y = count - if_else(residual_kernel > 0, residual_kernel * total_n, 0)), fill = c_data) +
  geom_step(aes(y = density_kernel * total_n, group = 1), direction = "mid", size = 0.2, color = c_line) +
  scale_fill_manual(values = c(c_data, c_excess),
                    name = element_blank()) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "", 
       y = "Count") +
  theme(axis.title.x = element_markdown()) +
  ylim(0, NA_real_) +
  theme(legend.position = "none",
        legend.background = element_blank(),
        panel.grid = element_line(color = c_grid))

p2_kernel_psyctests <- 
  ggplot(plot_data_psyctests, aes(alpha, residual_kernel * total_n, fill = excess)) + 
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col(aes(color = excess), size = 0.2) +
  scale_color_manual(values = c(c_line, "#FFFFFF00")) +
  geom_segment(x = 0.005, xend = 0.995, y = 0,yend=0, size = 0.2, color = c_line) +
  scale_fill_manual(values = c("white", c_excess),
                    guide = guide_legend(reverse = TRUE)) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = -200, to = 200, by = 50),
                     labels = label_number(accuracy = 1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       y = "Residual") +
  theme(legend.title = element_blank(),
        axis.title.x = element_markdown(),
        legend.position = "none",
        panel.background = element_rect(fill = c_lpbg),
        panel.grid = element_line(color = c_grid))  # c(0.23, 0.77), legend.background = element_blank()

p_kernel_psyctests <- 
  p1_kernel_psyctests + 
  p2_kernel_psyctests + 
  plot_layout(nrow = 2, heights = c(1.5, 1))

p_kernel_psyctests

ggsave("plots/p_kernel_psyctests.pdf",
       plot = p_kernel_psyctests,
       device = cairo_pdf,
       width = 6,
       height = 4.5,
       units = "in")

# ggsave("plots/p_kernel_psyctests.png",
#        plot = p_kernel_psyctests,
#        device = png,
#        width = 6,
#        height = 4.5,
#        units = "in")

```

### Quantify excess 

```{r}

data_inflation_kernel <- data_frequency %>%
  filter(missing == FALSE) %>%
  dplyr::select(alpha, 
                observed = freq, 
                predicted = density_kernel, 
                residual = residual_kernel) %>%
  mutate(predicted = predicted/100,
         residual = residual/100,
         inflation = (observed/predicted - 1),
         inflation_for_reporting = janitor::round_half_up(inflation*100, digits = 0),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                               TRUE ~ "non cutoff")))

```

- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.70]`% more observations of Cronbach's $\alpha$ = .70 than predicted.
- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.80]`% more observations of Cronbach's $\alpha$ = .80 than predicted.
- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.90]`% more observations of Cronbach's $\alpha$ = .90 than predicted.

### Permutation tests

.70, .80, and .90 against the rest:

```{r}

independence_test(residual ~ group_3_cutoffs,
                  data = data_inflation_kernel,
                  distribution = "exact",
                  alternative = "greater")

```

.70 against the rest:

```{r}

independence_test(residual ~ group_1_cutoff,
                  data = data_inflation_kernel,
                  distribution = "exact",
                  alternative = "greater")

```

## Caliper tests

See Gerber et al. (2010) "Publication Bias in Two Political Behavior Literatures"

Using alpha ± 0.01 calipers. 

The usual null hypothesis of no differences cannot be tested against, so instead I calculate over/under ratios for each 0.01 and its neighbor, i.e., ratio = count($\alpha_x$) / count($\alpha_{x-0.01}$). Because very few counts are present in \alpha < .50, which makes the ratios very poorly estimated, I exclude these values. The hypothesis that the ratio for the cut-off score ratio being larger than the ratios calculated from non cut-offs is then tested via permuation test.

### Quantify excess

```{r}

data_caliper <- data_processed_binned %>% 
  mutate(n_total = n()) %>% 
  group_by(alpha) %>% 
  summarise(count = sum(!is.na(alpha)))

data_caliper |>
  filter(alpha %in% c(.69, .70, .79, .80, .89, .90)) |>
  mutate(type = ifelse(alpha %in% c(.70, .80, .90), "threshold", "nonthreshold"),
         cutoff = case_when(alpha %in% c(.69, .70) ~ .70,
                            alpha %in% c(.79, .80) ~ .80,
                            alpha %in% c(.89, .90) ~ .90)) |>
  select(-alpha) |>
  pivot_wider(names_from = type, 
              values_from = count) |>
  mutate(ratio = janitor::round_half_up(threshold/nonthreshold, 2)) |>
  kable() |>
  kable_classic(full_width = FALSE)

data_caliper_all <- data_caliper |>
  mutate(ratio = count/lag(count),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                              TRUE ~ "non cutoff")))

```

### Plot

```{r}

cbp2 <- c("grey", "#2A788EFF")

p_caliper_all_psyctests <- 
  data_caliper_all |>
  filter(alpha >= .50) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Cut-off", 
                          TRUE ~ "Non cut-off"),
         type = fct_relevel(type, "Non cut-off", "Cut-off")) |>
  #mutate(type = ifelse(ratio > 1, "1", "2")) |>
  ggplot(aes(x = alpha, y = ratio, fill = type, color = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  #geom_col(position = "stack") +
  geom_segment(aes(x = alpha,
                   xend = alpha,
                   y = 1, 
                   yend = ratio), size = 3) +
  #scale_color_viridis_d(direction = -1, begin = 0.2, end = 0.6, option = "plasma") +
  #scale_color_viridis_d(direction = -1, begin = 0.2, end = 0.55, option = "magma") +
  scale_color_manual(values = cbp2) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.05),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = 0, to = 2, by = 0.2),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       #y = "Ratio<br />n(&alpha;<sub>i</sub>) / n(&alpha;<sub>i-0.01</sub>)",
       y = "Calliper test ratio<br />(|&alpha;<sub>i</sub>| / |&alpha;<sub>i-0.01</sub>|)",
       color = "") +
  theme(legend.position = "bottom",
        axis.title.x = element_markdown(),
        axis.title.y = element_markdown())

p_caliper_all_psyctests

write_rds(p_caliper_all_psyctests, "plots/p_caliper_all_psyctests.rds")

ggsave("plots/p_caliper_all_psyctests.pdf",
       plot = p_caliper_all_psyctests,
       device = cairo_pdf,
       width = 6,
       height = 4,
       units = "in")

# ggsave("plots/p_caliper_all_psyctests.png",
#        plot = p_caliper_all_psyctests,
#        device = png,
#        width = 6,
#        height = 4,
#        units = "in")

```

Note that $|\alpha_i|$ refers to cardinality (i.e., count) rather than absolute value. Unfortunately these are annotated in the same way using vertical bars. 

Note excesses at .50 and .60 as well as .70.

### Permutation tests

.70/.69, .80/.79, and .90/.89 against the rest:

```{r}

independence_test(ratio ~ group_3_cutoffs,
                  data = filter(data_caliper_all, alpha >= .50),
                  distribution = "exact",
                  alternative = "greater")

```

.70/.69 against the rest:

```{r}

independence_test(ratio ~ group_1_cutoff,
                  data = filter(data_caliper_all, alpha >= .50),
                  distribution = "exact",
                  alternative = "greater")

```

# Original tests

## Kernel smoothing

### Model and plot

```{r}

data_included <- data_processed |>
  filter(test_type == "Original") |>
  mutate(alpha = alpha_all) |>
  filter(exclude_master == FALSE) 
  
nrow(data_included)

# create tibble containing all alpha bins, for a later join
all_alphas <- tibble(alpha = as.character(seq(0.01, 0.99, 0.01)),
                     freq = 0,
                     missing = TRUE)

data_processed_binned <- data_included %>% 
  pull(alpha) %>% 
  unlist() %>% 
  as.numeric() %>% 
  tibble(alpha = .) %>% 
  filter(alpha > 0, !is.na(alpha)) %>% 
  mutate(alpha = janitor::round_half_up(alpha, 2),
         alpha = case_when(alpha == 0 ~ 0.01,
                           alpha == 1 ~ 0.99,
                           TRUE ~ alpha))

data_frequency_temp <- data_processed_binned %>% 
  mutate(n_total = n()) %>% 
  group_by(alpha) %>% 
  summarise(freq = sum(!is.na(alpha))/first(n_total)) %>%
  # convert alpha to character to facilitate a join later
  mutate(alpha = as.character(alpha))

# kernel density estimation
data_density <- 
  density(data_processed_binned %>%
            pull(alpha),
          n      = length(seq(0.01, 0.99, 0.01)),
          from   = 0.01,
          to     = 0.99, 
          kernel = "gaussian",
          bw     = 0.01) # "nrd0" returns 0.01

data_frequency <- data_frequency_temp %>%
  # join the previous two tibbles to create a complete list of alpha bins
  bind_rows(all_alphas %>% anti_join(data_frequency_temp, by = "alpha")) %>%
  arrange(alpha, desc(freq)) %>%
  distinct(alpha, .keep_all = TRUE) %>%
  mutate(density_kernel = data_density$y,
         missing = ifelse(is.na(missing), FALSE, missing)) %>%
  mutate(residual_kernel = freq*100 - density_kernel,
         alpha = as.numeric(alpha),
         missing = ifelse(is.na(missing), FALSE, missing))

total_n <- nrow(data_processed_binned)/100

plot_data_psyctests <- data_processed_binned |>
  mutate(n_total = n()) |>
  group_by(alpha) |>
  summarise(count = sum(!is.na(alpha))) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Common reliability threshold",
                          TRUE ~ "Non-threshold"),
         type = fct_relevel(type, "Non-threshold", "Common reliability threshold")) |>
  right_join(data_frequency, by = "alpha") |>
  mutate(excess = if_else(residual_kernel > 0, "excess", "deficit"))# %>% 
# drop_na()

c_excess <- "#2A788EFF"
c_data <- "lightgrey"
c_line <- "black"
c_lpbg <- "white"
c_grid <- "#F0F0F0AA"

p1_kernel_psyctests <-
  ggplot(plot_data_psyctests, aes(alpha, y = count, fill = excess)) +
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col() +
  geom_col(aes(y = count - if_else(residual_kernel > 0, residual_kernel * total_n, 0)), fill = c_data) +
  geom_step(aes(y = density_kernel * total_n, group = 1), direction = "mid", size = 0.2, color = c_line) +
  scale_fill_manual(values = c(c_data, c_excess),
                    name = element_blank()) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "", 
       y = "Count") +
  theme(axis.title.x = element_markdown()) +
  ylim(0, NA_real_) +
  theme(legend.position = "none",
        legend.background = element_blank(),
        panel.grid = element_line(color = c_grid))

p2_kernel_psyctests <- 
  ggplot(plot_data_psyctests, aes(alpha, residual_kernel * total_n, fill = excess)) + 
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col(aes(color = excess), size = 0.2) +
  scale_color_manual(values = c(c_line, "#FFFFFF00")) +
  geom_segment(x = 0.005, xend = 0.995, y = 0,yend=0, size = 0.2, color = c_line) +
  scale_fill_manual(values = c("white", c_excess),
                    guide = guide_legend(reverse = TRUE)) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = -200, to = 200, by = 50),
                     labels = label_number(accuracy = 1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       y = "Residual") +
  theme(legend.title = element_blank(),
        axis.title.x = element_markdown(),
        legend.position = "none",
        panel.background = element_rect(fill = c_lpbg),
        panel.grid = element_line(color = c_grid))  # c(0.23, 0.77), legend.background = element_blank()

p_kernel_psyctests <- 
  p1_kernel_psyctests + 
  p2_kernel_psyctests + 
  plot_layout(nrow = 2, heights = c(1.5, 1))

p_kernel_psyctests

ggsave("plots/p_kernel_psyctests_originaltests.pdf",
       plot = p_kernel_psyctests,
       device = cairo_pdf,
       width = 6,
       height = 4.5,
       units = "in")

# ggsave("plots/p_kernel_psyctests_originaltests.png",
#        plot = p_kernel_psyctests,
#        device = png,
#        width = 6,
#        height = 4.5,
#        units = "in")

```

### Quantify excess 

```{r}

data_inflation_kernel <- data_frequency %>%
  filter(missing == FALSE) %>%
  dplyr::select(alpha, 
                observed = freq, 
                predicted = density_kernel, 
                residual = residual_kernel) %>%
  mutate(predicted = predicted/100,
         residual = residual/100,
         inflation = (observed/predicted - 1),
         inflation_for_reporting = janitor::round_half_up(inflation*100, digits = 0),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                               TRUE ~ "non cutoff")))

```

- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.70]`% more observations of Cronbach's $\alpha$ = .70 than predicted.
- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.80]`% more observations of Cronbach's $\alpha$ = .80 than predicted.
- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.90]`% more observations of Cronbach's $\alpha$ = .90 than predicted.

### Permutation tests

.70, .80, and .90 against the rest:

```{r}

independence_test(residual ~ group_3_cutoffs,
                  data = data_inflation_kernel,
                  distribution = "exact",
                  alternative = "greater")

```

.70 against the rest:

```{r}

independence_test(residual ~ group_1_cutoff,
                  data = data_inflation_kernel,
                  distribution = "exact",
                  alternative = "greater")

```

## Caliper tests

See Gerber et al. (2010) "Publication Bias in Two Political Behavior Literatures"

Using alpha ± 0.01 calipers. 

The usual null hypothesis of no differences cannot be tested against, so instead I calculate over/under ratios for each 0.01 and its neighbor, i.e., ratio = count($\alpha_x$) / count($\alpha_{x-0.01}$). Because very few counts are present in \alpha < .50, which makes the ratios very poorly estimated, I exclude these values. The hypothesis that the ratio for the cut-off score ratio being larger than the ratios calculated from non cut-offs is then tested via permuation test.

### Quantify excess

```{r}

data_caliper <- data_processed_binned %>% 
  mutate(n_total = n()) %>% 
  group_by(alpha) %>% 
  summarise(count = sum(!is.na(alpha)))

data_caliper |>
  filter(alpha %in% c(.69, .70, .79, .80, .89, .90)) |>
  mutate(type = ifelse(alpha %in% c(.70, .80, .90), "threshold", "nonthreshold"),
         cutoff = case_when(alpha %in% c(.69, .70) ~ .70,
                            alpha %in% c(.79, .80) ~ .80,
                            alpha %in% c(.89, .90) ~ .90)) |>
  select(-alpha) |>
  pivot_wider(names_from = type, 
              values_from = count) |>
  mutate(ratio = janitor::round_half_up(threshold/nonthreshold, 2)) |>
  kable() |>
  kable_classic(full_width = FALSE)

data_caliper_all <- data_caliper |>
  mutate(ratio = count/lag(count),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                              TRUE ~ "non cutoff")))

```

### Plot

```{r}

cbp2 <- c("grey", "#2A788EFF")

p_caliper_all_psyctests <- 
  data_caliper_all |>
  filter(alpha >= .50) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Cut-off", 
                          TRUE ~ "Non cut-off"),
         type = fct_relevel(type, "Non cut-off", "Cut-off")) |>
  #mutate(type = ifelse(ratio > 1, "1", "2")) |>
  ggplot(aes(x = alpha, y = ratio, fill = type, color = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  #geom_col(position = "stack") +
  geom_segment(aes(x = alpha,
                   xend = alpha,
                   y = 1, 
                   yend = ratio), size = 3) +
  #scale_color_viridis_d(direction = -1, begin = 0.2, end = 0.6, option = "plasma") +
  #scale_color_viridis_d(direction = -1, begin = 0.2, end = 0.55, option = "magma") +
  scale_color_manual(values = cbp2) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.05),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = 0, to = 2, by = 0.2),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       #y = "Ratio<br />n(&alpha;<sub>i</sub>) / n(&alpha;<sub>i-0.01</sub>)",
       y = "Calliper test ratio<br />(|&alpha;<sub>i</sub>| / |&alpha;<sub>i-0.01</sub>|)",
       color = "") +
  theme(legend.position = "bottom",
        axis.title.x = element_markdown(),
        axis.title.y = element_markdown())

p_caliper_all_psyctests

write_rds(p_caliper_all_psyctests, "plots/p_caliper_all_psyctests_original.rds")

ggsave("plots/p_caliper_all_psyctests_original.pdf",
       plot = p_caliper_all_psyctests,
       device = cairo_pdf,
       width = 6,
       height = 4,
       units = "in")

# ggsave("plots/p_caliper_all_psyctests_original.png",
#        plot = p_caliper_all_psyctests,
#        device = png,
#        width = 6,
#        height = 4,
#        units = "in")

```

Note that $|\alpha_i|$ refers to cardinality (i.e., count) rather than absolute value. Unfortunately these are annotated in the same way using vertical bars. 

Note excesses at .50 and .60 as well as .70.

### Permutation tests

.70/.69, .80/.79, and .90/.89 against the rest:

```{r}

independence_test(ratio ~ group_3_cutoffs,
                  data = filter(data_caliper_all, alpha >= .50),
                  distribution = "exact",
                  alternative = "greater")

```

.70/.69 against the rest:

```{r}

independence_test(ratio ~ group_1_cutoff,
                  data = filter(data_caliper_all, alpha >= .50),
                  distribution = "exact",
                  alternative = "greater")

```

# Revisions & Translations

## Kernel smoothing

### Model and plot

```{r}

data_included <- data_processed |>
  filter(test_type %in% c("Revision", "Translation")) |>
  mutate(alpha = alpha_all) |>
  filter(exclude_master == FALSE) 
  
nrow(data_included)

# create tibble containing all alpha bins, for a later join
all_alphas <- tibble(alpha = as.character(seq(0.01, 0.99, 0.01)),
                     freq = 0,
                     missing = TRUE)

data_processed_binned <- data_included %>% 
  pull(alpha) %>% 
  unlist() %>% 
  as.numeric() %>% 
  tibble(alpha = .) %>% 
  filter(alpha > 0, !is.na(alpha)) %>% 
  mutate(alpha = janitor::round_half_up(alpha, 2),
         alpha = case_when(alpha == 0 ~ 0.01,
                           alpha == 1 ~ 0.99,
                           TRUE ~ alpha))

data_frequency_temp <- data_processed_binned %>% 
  mutate(n_total = n()) %>% 
  group_by(alpha) %>% 
  summarise(freq = sum(!is.na(alpha))/first(n_total)) %>%
  # convert alpha to character to facilitate a join later
  mutate(alpha = as.character(alpha))

# kernel density estimation
data_density <- 
  density(data_processed_binned %>%
            pull(alpha),
          n      = length(seq(0.01, 0.99, 0.01)),
          from   = 0.01,
          to     = 0.99, 
          kernel = "gaussian",
          bw     = 0.01) # "nrd0" returns 0.01

data_frequency <- data_frequency_temp %>%
  # join the previous two tibbles to create a complete list of alpha bins
  bind_rows(all_alphas %>% anti_join(data_frequency_temp, by = "alpha")) %>%
  arrange(alpha, desc(freq)) %>%
  distinct(alpha, .keep_all = TRUE) %>%
  mutate(density_kernel = data_density$y,
         missing = ifelse(is.na(missing), FALSE, missing)) %>%
  mutate(residual_kernel = freq*100 - density_kernel,
         alpha = as.numeric(alpha),
         missing = ifelse(is.na(missing), FALSE, missing))

total_n <- nrow(data_processed_binned)/100

plot_data_psyctests <- data_processed_binned |>
  mutate(n_total = n()) |>
  group_by(alpha) |>
  summarise(count = sum(!is.na(alpha))) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Common reliability threshold",
                          TRUE ~ "Non-threshold"),
         type = fct_relevel(type, "Non-threshold", "Common reliability threshold")) |>
  right_join(data_frequency, by = "alpha") |>
  mutate(excess = if_else(residual_kernel > 0, "excess", "deficit"))# %>% 
# drop_na()

c_excess <- "#2A788EFF"
c_data <- "lightgrey"
c_line <- "black"
c_lpbg <- "white"
c_grid <- "#F0F0F0AA"

p1_kernel_psyctests <-
  ggplot(plot_data_psyctests, aes(alpha, y = count, fill = excess)) +
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col() +
  geom_col(aes(y = count - if_else(residual_kernel > 0, residual_kernel * total_n, 0)), fill = c_data) +
  geom_step(aes(y = density_kernel * total_n, group = 1), direction = "mid", size = 0.2, color = c_line) +
  scale_fill_manual(values = c(c_data, c_excess),
                    name = element_blank()) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "", 
       y = "Count") +
  theme(axis.title.x = element_markdown()) +
  ylim(0, NA_real_) +
  theme(legend.position = "none",
        legend.background = element_blank(),
        panel.grid = element_line(color = c_grid))

p2_kernel_psyctests <- 
  ggplot(plot_data_psyctests, aes(alpha, residual_kernel * total_n, fill = excess)) + 
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col(aes(color = excess), size = 0.2) +
  scale_color_manual(values = c(c_line, "#FFFFFF00")) +
  geom_segment(x = 0.005, xend = 0.995, y = 0,yend=0, size = 0.2, color = c_line) +
  scale_fill_manual(values = c("white", c_excess),
                    guide = guide_legend(reverse = TRUE)) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = -200, to = 200, by = 50),
                     labels = label_number(accuracy = 1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       y = "Residual") +
  theme(legend.title = element_blank(),
        axis.title.x = element_markdown(),
        legend.position = "none",
        panel.background = element_rect(fill = c_lpbg),
        panel.grid = element_line(color = c_grid))  # c(0.23, 0.77), legend.background = element_blank()

p_kernel_psyctests <- 
  p1_kernel_psyctests + 
  p2_kernel_psyctests + 
  plot_layout(nrow = 2, heights = c(1.5, 1))

p_kernel_psyctests

ggsave("plots/p_kernel_psyctests_revisionstranslations.pdf",
       plot = p_kernel_psyctests,
       device = cairo_pdf,
       width = 6,
       height = 4.5,
       units = "in")

# ggsave("plots/p_kernel_psyctests_revisionstranslations.png",
#        plot = p_kernel_psyctests,
#        device = png,
#        width = 6,
#        height = 4.5,
#        units = "in")

```

### Quantify excess 

```{r}

data_inflation_kernel <- data_frequency %>%
  filter(missing == FALSE) %>%
  dplyr::select(alpha, 
                observed = freq, 
                predicted = density_kernel, 
                residual = residual_kernel) %>%
  mutate(predicted = predicted/100,
         residual = residual/100,
         inflation = (observed/predicted - 1),
         inflation_for_reporting = janitor::round_half_up(inflation*100, digits = 0),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                               TRUE ~ "non cutoff")))

```

- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.70]`% more observations of Cronbach's $\alpha$ = .70 than predicted.
- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.80]`% more observations of Cronbach's $\alpha$ = .80 than predicted.
- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.90]`% more observations of Cronbach's $\alpha$ = .90 than predicted.

### Permutation tests

.70, .80, and .90 against the rest:

```{r}

independence_test(residual ~ group_3_cutoffs,
                  data = data_inflation_kernel,
                  distribution = "exact",
                  alternative = "greater")

```

.70 against the rest:

```{r}

independence_test(residual ~ group_1_cutoff,
                  data = data_inflation_kernel,
                  distribution = "exact",
                  alternative = "greater")

```

## Caliper tests

See Gerber et al. (2010) "Publication Bias in Two Political Behavior Literatures"

Using alpha ± 0.01 calipers. 

The usual null hypothesis of no differences cannot be tested against, so instead I calculate over/under ratios for each 0.01 and its neighbor, i.e., ratio = count($\alpha_x$) / count($\alpha_{x-0.01}$). Because very few counts are present in \alpha < .50, which makes the ratios very poorly estimated, I exclude these values. The hypothesis that the ratio for the cut-off score ratio being larger than the ratios calculated from non cut-offs is then tested via permuation test.

### Quantify excess

```{r}

data_caliper <- data_processed_binned %>% 
  mutate(n_total = n()) %>% 
  group_by(alpha) %>% 
  summarise(count = sum(!is.na(alpha)))

data_caliper |>
  filter(alpha %in% c(.69, .70, .79, .80, .89, .90)) |>
  mutate(type = ifelse(alpha %in% c(.70, .80, .90), "threshold", "nonthreshold"),
         cutoff = case_when(alpha %in% c(.69, .70) ~ .70,
                            alpha %in% c(.79, .80) ~ .80,
                            alpha %in% c(.89, .90) ~ .90)) |>
  select(-alpha) |>
  pivot_wider(names_from = type, 
              values_from = count) |>
  mutate(ratio = janitor::round_half_up(threshold/nonthreshold, 2)) |>
  kable() |>
  kable_classic(full_width = FALSE)

data_caliper_all <- data_caliper |>
  mutate(ratio = count/lag(count),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                              TRUE ~ "non cutoff")))

```

### Plot

```{r}

cbp2 <- c("grey", "#2A788EFF")

p_caliper_all_psyctests <- 
  data_caliper_all |>
  filter(alpha >= .50) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Cut-off", 
                          TRUE ~ "Non cut-off"),
         type = fct_relevel(type, "Non cut-off", "Cut-off")) |>
  #mutate(type = ifelse(ratio > 1, "1", "2")) |>
  ggplot(aes(x = alpha, y = ratio, fill = type, color = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  #geom_col(position = "stack") +
  geom_segment(aes(x = alpha,
                   xend = alpha,
                   y = 1, 
                   yend = ratio), size = 3) +
  #scale_color_viridis_d(direction = -1, begin = 0.2, end = 0.6, option = "plasma") +
  #scale_color_viridis_d(direction = -1, begin = 0.2, end = 0.55, option = "magma") +
  scale_color_manual(values = cbp2) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.05),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = 0, to = 2, by = 0.2),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       #y = "Ratio<br />n(&alpha;<sub>i</sub>) / n(&alpha;<sub>i-0.01</sub>)",
       y = "Calliper test ratio<br />(|&alpha;<sub>i</sub>| / |&alpha;<sub>i-0.01</sub>|)",
       color = "") +
  theme(legend.position = "bottom",
        axis.title.x = element_markdown(),
        axis.title.y = element_markdown())

p_caliper_all_psyctests

write_rds(p_caliper_all_psyctests,
          "plots/p_caliper_all_psyctests_revisionstranslations.rds")

ggsave("plots/p_caliper_all_psyctests_revisionstranslations.pdf",
       plot = p_caliper_all_psyctests,
       device = cairo_pdf,
       width = 6,
       height = 4,
       units = "in")

# ggsave("plots/p_caliper_all_psyctests_revisionstranslations.png",
#        plot = p_caliper_all_psyctests,
#        device = png,
#        width = 6,
#        height = 4,
#        units = "in")

```

Note that $|\alpha_i|$ refers to cardinality (i.e., count) rather than absolute value. Unfortunately these are annotated in the same way using vertical bars. 

Note excesses at .50 and .60 as well as .70.

### Permutation tests

.70/.69, .80/.79, and .90/.89 against the rest:

```{r}

independence_test(ratio ~ group_3_cutoffs,
                  data = filter(data_caliper_all, alpha >= .50),
                  distribution = "exact",
                  alternative = "greater")

```

.70/.69 against the rest:

```{r}

independence_test(ratio ~ group_1_cutoff,
                  data = filter(data_caliper_all, alpha >= .50),
                  distribution = "exact",
                  alternative = "greater")

```

# Session info

```{r}

sessionInfo()

```




