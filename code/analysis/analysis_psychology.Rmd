---
title: "A excess of Cronbach's α values at rule-of-thumb cut-offs"
subtitle: "Analyses of Psychology/APA dataset"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- NA

```{r setup, include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

```

# Dependencies

```{r}

library(tidyverse)
library(scales)
library(betareg)
library(broom)
library(extraDistr)
library(patchwork)
library(coin)
library(knitr)
library(kableExtra)
library(ggtext)


dir.create("plots")

# disable scientific notation
options(scipen=999)

# set seed
set.seed(42)

```

# Get data

```{r}

data_processed <- read_csv("../../data/processed/psychology/data_processed_psychology.csv")

data_processed_trimmed <- data_processed |>
  filter(!is.na(alpha) & exclude_master == FALSE)

data_processed_binned <- data_processed_trimmed %>%
  # round the alpha values to 2 decimal places, using standard rounding method
  # recode alpha values of 0 or 1 to .01 or .99, in order to be able to fit beta regression
  # nb none present in dataset
  mutate(alpha = janitor::round_half_up(alpha, 2),
         alpha = case_when(alpha == 0 ~ 0.01,
                           alpha == 1 ~ 0.99,
                           TRUE ~ alpha)) 

# dat <- data_processed_trimmed |>
#   filter(exclude_master == FALSE) |>
#   group_by(doi) |>
#   mutate(n_estimates = n()) |>
#   ungroup() |>
#   select(doi, n_estimates, exemplar, alpha, all)

```

# Descriptives

```{r}

# data_fulltexts <-
#   tibble(filename = list.files("../../data/apa_articles",
#                                pattern    = "*.txt",
#                                recursive  = TRUE,
#                                full.names = TRUE))
# 
# n_doi <- nrow(data_fulltexts)
# n_doi$n_doi
# # [1] 74470

n_doi <- 74470

cat("n articles =", 
      n_doi, "\n")


n_exclusions <- data_processed |>
  filter(exclude_master == TRUE) |>
  count(name = "n_exclusions") |>
  pull(n_exclusions)

cat("n exclusions =", n_exclusions, "\n")


n_estimates_after_exclusions <- data_processed_trimmed |>
  count(name = "n_estimates") |>
  pull(n_estimates)

cat("n alpha estimates after exclusions =", 
      n_estimates_after_exclusions, "\n")


dois_with_valid_alpha <- nrow(distinct(data_processed_trimmed, doi))

cat("n articles with 1+ alpha estimate after exclusions = ", dois_with_valid_alpha, "\n")

proportion_with_valid_alpha <- 
  janitor::round_half_up(dois_with_valid_alpha / n_doi*100, 1)

cat("proportion of articles with 1+ alpha estimates after exclusions =",
      proportion_with_valid_alpha, "\n")

```

# Kernel smoothing

## Model and plot

```{r}

# create tibble containing all alpha bins, for a later join
all_alphas <- tibble(alpha = as.character(seq(0.01, 0.99, 0.01)),
                     freq = 0,
                     missing = TRUE)

data_frequency_temp <- data_processed_binned %>% 
  mutate(n_total = n()) %>% 
  group_by(alpha) %>% 
  summarise(freq = sum(!is.na(alpha))/first(n_total)) %>%
  # convert alpha to character to facilitate a join later
  mutate(alpha = as.character(alpha))

# kernel density estimation
data_density <- 
  density(data_processed_binned %>%
            pull(alpha),
          n      = length(seq(0.01, 0.99, 0.01)),
          from   = 0.01,
          to     = 0.99, 
          kernel = "gaussian",
          bw     = 0.01) # "nrd0" returns 0.01

data_frequency <-
  # join the previous two tibbles to create a complete list of alpha bins
  data_frequency_temp %>%
  bind_rows(all_alphas %>% anti_join(data_frequency_temp, by = "alpha")) %>%
  arrange(alpha, desc(freq)) %>%
  distinct(alpha, .keep_all = TRUE) %>%
  mutate(density_kernel = data_density$y,
         missing = ifelse(is.na(missing), FALSE, missing)) %>%
  mutate(residual_kernel = freq*100 - density_kernel,
         alpha = as.numeric(alpha),
         missing = ifelse(is.na(missing), FALSE, missing))

data_diff <- data_frequency %>%
  mutate(frequency = freq*100,
         frequency_without_residual_kernel = if_else(residual_kernel > 0, frequency - residual_kernel, frequency),
         pos_resid_kernel = residual_kernel > 0,
         residual_kernel = if_else(residual_kernel > 0, residual_kernel, -1 * residual_kernel)) %>%
  dplyr::select(alpha,
                #fitted,
                density_kernel,
                pos_resid_kernel,
                frequency_without_residual_kernel,
                residual_kernel) %>%
  pivot_longer(names_to = "type",
               values_to = "residual_kernel",
               c(frequency_without_residual_kernel, residual_kernel))


color_1 <- scales::viridis_pal()(11)[3]
color_2 <- scales::viridis_pal()(11)[7]

total_n <- nrow(data_processed_binned)/100

p1_kernel <-
  data_diff %>%  
  mutate(type = factor(case_when(
    type == "frequency_without_residual_kernel" ~ "3",
    pos_resid_kernel ~ "2",
    TRUE ~ "1"))
  ) %>% 
  ggplot(., aes(alpha, y = residual_kernel * total_n, fill = type)) + 
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col(position = "stack") +
  geom_step(aes(y = density_kernel * total_n, group = 1), direction = "mid", size = 0.2) +
  #ggrepel::geom_text_repel(aes(y = residual_kernel * total_n, label = if_else(type %in% c("2", "1") & alpha %in% c(0.7, 0.8, 0.9), round(residual_kernel*total_n), NA_real_)), position = "stack") +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_fill_manual(values = c("3" = "darkgray", "2" = color_2, "1" = color_1),
                    guide = "none") +
  scale_alpha_manual(values = c("3" = 0.35, "2" = 1, "1" = 1)) +
  theme_bw() +
  labs(x = "", #"Cronbach's &alpha;",
       y = "Count") +
  theme(axis.title.x = element_markdown()) +
  ylim(0, 1800)

p2_kernel <- 
  ggplot(data_frequency, aes(alpha, residual_kernel * total_n, fill = residual_kernel > 0)) + 
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col() +
  geom_hline(yintercept = 0, size = 0.2) +
  scale_fill_manual(values = c("TRUE" = color_2, "FALSE" = color_1), guide = "none") +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = -100, to = 100, by = 25),
                     labels = label_number(accuracy = 1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       y = "Residual") +
  theme(legend.position = "none",
        axis.title.x = element_markdown())

p_kernel <- p1_kernel + p2_kernel + plot_layout(nrow = 2, heights = c(0.5, 0.5))

p_kernel

write_rds(p_kernel, "plots/p_kernel_psychology.rds")

ggsave("plots/p_kernel_psychology.pdf", 
       plot = p_kernel, 
       width = 6,
       height = 4,
       units = "in")

```

### Alt 

```{r}

# cbp1 <- c("grey", "#56B4E9", "#E69F00", "#009E73",
#           "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# 
# library(viridisLite)
# 
# viridis(n = 1, begin = 0.4, end = 0.4)

cbp1 <- c("grey", "#2A788EFF")

plot_data_psych <- data_processed_binned |>
  mutate(n_total = n()) |>
  group_by(alpha) |>
  summarise(count = sum(!is.na(alpha))) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Cut-off",
                          TRUE ~ "Non cut-off"),
         type = fct_relevel(type, "Non cut-off", "Cut-off")) |>
  right_join(data_frequency, by = "alpha") |>
  drop_na()

p1_kernel_alt_psych <-
  ggplot(plot_data_psych, aes(alpha, y = count, fill = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col(position = "stack") +
  geom_step(aes(y = density_kernel * total_n, group = 1), direction = "mid", size = 0.3) +
  #scale_fill_viridis_d(direction = -1, begin = 0.2, end = 0.65) +
  scale_fill_manual(values = cbp1) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  # scale_alpha_manual(values = c("3" = 0.35, "2" = 1, "1" = 1)) +
  theme_bw() +
  labs(x = "", # expression("Cronbach's" ~ alpha),
       y = "Count",
       fill = "") +
  theme(axis.title.x = element_markdown()) +
  ylim(0, 1800) +
  theme(legend.position = "none")

p2_kernel_alt_psych <- 
  ggplot(plot_data_psych, aes(alpha, residual_kernel * total_n, fill = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col() +
  geom_hline(yintercept = 0, size = 0.2) +
  #scale_fill_manual(values = c("TRUE" = color_2, "FALSE" = color_1), guide = "none") +
  scale_fill_manual(values = cbp1) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = -200, to = 200, by = 25),
                     labels = label_number(accuracy = 1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       y = "Residual",
       fill = "") +
  theme(legend.position = "bottom",
        axis.title.x = element_markdown())

p_kernel_alt_psych <- 
  p1_kernel_alt_psych + 
  p2_kernel_alt_psych + 
  plot_layout(nrow = 2, heights = c(0.5, 0.5))

p_kernel_alt_psych

write_rds(p_kernel_alt_psych, "plots/p_kernel_alt_psychology.rds")

ggsave("plots/p_kernel_alt_psychology.pdf",
       plot = p_kernel_alt_psych,
       width = 6,
       height = 4,
       units = "in")

```

## Quantify excess 

```{r}

data_inflation_kernel <- data_frequency %>%
  filter(missing == FALSE) %>%
  dplyr::select(alpha, 
                observed = freq, 
                predicted = density_kernel, 
                residual = residual_kernel) %>%
  mutate(predicted = predicted/100,
         residual = residual/100,
         inflation = (observed/predicted - 1),
         inflation_for_reporting = janitor::round_half_up(inflation*100, digits = 0),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                               TRUE ~ "non cutoff")))

```

- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.70]`% more observations of Cronbach's $\alpha$ = .70 than predicted.
- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.80]`% more observations of Cronbach's $\alpha$ = .80 than predicted.
- There were `r data_inflation_kernel$inflation_for_reporting[data_inflation_kernel$alpha == 0.90]`% more observations of Cronbach's $\alpha$ = .90 than predicted.

## Permutation tests

.70, .80, and .90 against the rest:

```{r}

independence_test(residual ~ group_3_cutoffs,
                  data = data_inflation_kernel,
                  distribution = "exact",
                  alternative = "greater")

```

.70 against the rest:

```{r}

independence_test(residual ~ group_1_cutoff,
                  data = data_inflation_kernel,
                  distribution = "exact",
                  alternative = "greater")

```

# Caliper tests

See Gerber et al. (2010) "Publication Bias in Two Political Behavior Literatures"

Using alpha ± 0.01 calipers. 

The usual null hypothesis of no differences cannot be tested against, so instead I calculate over/under ratios for each 0.01 and its neighbour, i.e., ratio = count($\alpha_x$) / count($\alpha_{x-0.01}$). Because very few counts are present in \alpha < .50, which makes the ratios very poorly estimated, I exclude these values. The hypothesis that the ratio for the cut-off score ratio being larger than the ratios calculated from non cut-offs is then tested via permuation test.

## Quantify excess

```{r}

data_caliper <- data_processed_binned %>% 
  mutate(n_total = n()) %>% 
  group_by(alpha) %>% 
  summarise(count = sum(!is.na(alpha)))

data_caliper |>
  filter(alpha %in% c(.69, .70, .79, .80, .89, .90)) |>
  mutate(type = ifelse(alpha %in% c(.70, .80, .90), "threshold", "nonthreshold"),
         cutoff = case_when(alpha %in% c(.69, .70) ~ .70,
                            alpha %in% c(.79, .80) ~ .80,
                            alpha %in% c(.89, .90) ~ .90)) |>
  select(-alpha) |>
  pivot_wider(names_from = type, 
              values_from = count) |>
  mutate(ratio = janitor::round_half_up(threshold/nonthreshold, 2)) |>
  kable() |>
  kable_classic(full_width = FALSE)

data_caliper_all <- data_caliper |>
  mutate(ratio = count/lag(count),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                              TRUE ~ "non cutoff")))

```

## Plot

```{r}

cbp2 <- c("grey", "#2A788EFF")

p_caliper_all_psychology <-
  data_caliper_all |>
  filter(alpha >= .50) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Cut-off", 
                          TRUE ~ "Other"),
         type = fct_relevel(type, "Other", "Cut-off")) |>
  #mutate(type = ifelse(ratio > 1, "1", "2")) |>
  ggplot(aes(x = alpha, y = ratio, fill = type, color = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  #geom_col(position = "stack") +
  geom_segment(aes(x = alpha,
                   xend = alpha,
                   y = 1, 
                   yend = ratio), size = 3) +
  #scale_color_viridis_d(direction = -1, begin = 0.2, end = 0.6, option = "plasma") +
  #scale_color_viridis_d(direction = -1, begin = 0.2, end = 0.55, option = "magma") +
  scale_color_manual(values = cbp2) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.05),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = 0, to = 2, by = 0.2),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       #y = "Ratio<br />n(&alpha;<sub>i</sub>) / n(&alpha;<sub>i-0.01</sub>)",
       y = "Calliper test ratio<br />(|&alpha;<sub>i</sub>| / |&alpha;<sub>i-0.01</sub>|)",
       color = "") +
  theme(legend.position = "bottom",
        axis.title.x = element_markdown(),
        axis.title.y = element_markdown())

p_caliper_all_psychology

write_rds(p_caliper_all_psychology, "plots/p_caliper_all_psychology.rds")

ggsave("plots/p_caliper_all_psychology.pdf",
       plot = p_caliper_all_psychology,
       width = 6,
       height = 4,
       units = "in")

```

Note that $|\alpha_i|$ refers to cardinality (i.e., count) rather than absolute value. Unfortunately these are annotated in the same way using vertical bars. 

## Permutation tests

.70/.69, .80/.79, and .90/.89 against the rest:

```{r}

independence_test(ratio ~ group_3_cutoffs,
                  data = filter(data_caliper_all, alpha >= .50),
                  distribution = "exact",
                  alternative = "greater")

```

.70/.69 against the rest:

```{r}

independence_test(ratio ~ group_1_cutoff,
                  data = filter(data_caliper_all, alpha >= .50),
                  distribution = "exact",
                  alternative = "greater")

```

# Beta regression

Beta regression was also explored, but it had many more assumptions and poorer fit (e.g., large degree of unmodelled variance around $\alpha$ of .85 to .95), so it was rejected in favor of kernel smoothing. It is reported here for transparency.

## Model and plot

```{r}

# solution from https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#interpreting-coefficients

model_beta <- data_processed_binned %>%
  betareg(alpha ~ 1 | 1, 
          link = "logit",
          data = .)

beta_mu_intercept <- model_beta %>%
  tidy() %>%
  filter(component == "mean", term == "(Intercept)") %>%
  pull(estimate)

beta_phi_intercept <- model_beta %>%
  tidy() %>%
  filter(component == "precision", term == "(Intercept)") %>%
  pull(estimate)

data_frequency$density_beta <-
  extraDistr::dprop(x = data_frequency$alpha,
                    size = exp(beta_phi_intercept),
                    mean = plogis(beta_mu_intercept))

data_frequency <- data_frequency %>%
  mutate(residual_beta = freq*100 - density_beta,
         alpha = as.numeric(alpha),
         missing = ifelse(is.na(missing), FALSE, missing))

data_diff <- data_frequency %>%
  mutate(frequency = 100*freq,
         frequency_without_residual_beta = if_else(residual_beta > 0, frequency - residual_beta, frequency),
         pos_resid_beta = residual_beta > 0,
         residual_beta = if_else(residual_beta > 0, residual_beta, -1 * residual_beta)) %>%
  dplyr::select(alpha,
                density_beta,
                pos_resid_beta,
                frequency_without_residual_beta,
                residual_beta) %>%
  pivot_longer(names_to = "type",
               values_to = "residual_beta",
               c(frequency_without_residual_beta, residual_beta))


color_1 <- scales::viridis_pal()(11)[3]
color_2 <- scales::viridis_pal()(11)[7]

total_n <- nrow(data_processed_binned)/100

p1_beta <-
  data_diff %>%  
  mutate(type = factor(case_when(
    type == "frequency_without_residual_beta" ~ "3",
    pos_resid_beta ~ "2",
    TRUE ~ "1"))
  ) %>%
  ggplot(., aes(alpha, y = residual_beta * total_n, fill = type)) +
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col(position = "stack") +
  geom_step(aes(y = density_beta * total_n, group = 1), direction = "mid", size = 0.2) +
  #ggrepel::geom_text_repel(aes(y = residual_beta * total_n, label = if_else(type %in% c("2", "1") & alpha %in% c(0.7, 0.8, 0.9), round(residual_beta*total_n), NA_real_)), position = "stack") +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_fill_manual(values = c("3" = "darkgray", "2" = color_2, "1" = color_1),
                    guide = "none") +
  scale_alpha_manual(values = c("3" = 0.35, "2" = 1, "1" = 1)) +
  theme_bw() +
  labs(x = "", #"Cronbach's &alpha;",
       y = "Count")

p2_beta <-
  ggplot(data_frequency, aes(alpha, residual_beta * total_n, fill = residual_beta > 0)) +
  geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col() +
  geom_hline(yintercept = 0, size = 0.2) +
  scale_fill_manual(values = c("TRUE" = color_2, "FALSE" = color_1), guide = "none") +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = -300, to = 300, by = 50),
                     labels = label_number(accuracy = 1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       y = "Residual",
       fill = "") +
  theme(legend.position = "bottom",
        axis.title.x = element_markdown())

p_beta <- p1_beta + p2_beta + plot_layout(nrow = 2, heights = c(0.5, 0.5))

p_beta

# ggsave("plots/p_beta_psychology.pdf", 
#        plot = p_beta, 
#        width = 6,
#        height = 4,
#        units = "in")

```

## Quantify excess 

```{r}

data_inflation_beta <- data_frequency %>%
  filter(missing == FALSE) %>%
  dplyr::select(alpha, 
                observed = freq, 
                predicted = density_beta, 
                residual = residual_beta) %>%
  mutate(predicted = predicted/100,
         residual = residual/100,
         inflation = (observed/predicted - 1),
         inflation_for_reporting = janitor::round_half_up(inflation*100, digits = 0),
         group_3_cutoffs = as.factor(case_when(alpha %in% c(.70, .80, .90) ~ "cutoff",
                                               TRUE ~ "non cutoff")),
         group_1_cutoff = as.factor(case_when(alpha %in% c(.70) ~ "cutoff",
                                               TRUE ~ "non cutoff")))

```

- There were `r data_inflation_beta$inflation_for_reporting[data_inflation_beta$alpha == 0.70]`% more observations of Cronbach's $a$ = .70 than predicted.
- There were `r data_inflation_beta$inflation_for_reporting[data_inflation_beta$alpha == 0.80]`% more observations of Cronbach's $a$ = .80 than predicted.
- There were `r data_inflation_beta$inflation_for_reporting[data_inflation_beta$alpha == 0.90]`% more observations of Cronbach's $a$ = .90 than predicted.

## Permutation test

.70, .80, and .90 against the rest:

```{r}

independence_test(residual ~ group_3_cutoffs,
                  data = data_inflation_beta,
                  distribution = "exact",
                  alternative = "greater")

```

.70 against the rest:

```{r}

independence_test(residual ~ group_1_cutoff,
                  data = data_inflation_beta,
                  distribution = "exact",
                  alternative = "greater")

```

# Plots comparing kernel smoothing and caliper tests

## Full range

```{r}

cbp1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot_data <- data_processed_binned |>
  mutate(n_total = n()) |>
  group_by(alpha) |>
  summarise(count = sum(!is.na(alpha))) |>
  mutate(type = case_when(alpha %in% c(.70, .80, .90) ~ "Cut-off",
                          alpha %in% c(.69, .79, .89) ~ "Pre cut-off",
                          TRUE ~ "Other"),
         type = fct_relevel(type, "Other", "Pre cut-off", "Cut-off")) |>
  right_join(data_frequency, by = "alpha") |>
  drop_na()

p1_kernel_alt <-
  ggplot(plot_data, aes(alpha, y = count, fill = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col(position = "stack") +
  geom_step(aes(y = density_kernel * total_n, group = 1), direction = "mid", size = 0.3) +
  #scale_fill_viridis_d(direction = -1, begin = 0.2, end = 0.65) +
  scale_fill_manual(values = cbp1) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  # scale_alpha_manual(values = c("3" = 0.35, "2" = 1, "1" = 1)) +
  theme_bw() +
  labs(x = "", # expression("Cronbach's" ~ alpha),
       y = "Count",
       fill = "") +
  # theme(axis.title.x = element_markdown()) +
  ylim(0, 1800) +
  theme(legend.position = "none")

p2_kernel_alt <- 
  ggplot(plot_data, aes(alpha, residual_kernel * total_n, fill = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col() +
  geom_hline(yintercept = 0, size = 0.2) +
  #scale_fill_manual(values = c("TRUE" = color_2, "FALSE" = color_1), guide = "none") +
  scale_fill_manual(values = cbp1) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),
                     labels = label_number(accuracy = 0.1),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = -200, to = 200, by = 50),
                     labels = label_number(accuracy = 1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       y = "Residual",
       fill = "") +
  theme(legend.position = "bottom",
        axis.title.x = element_markdown())

p_kernel_alt <- p1_kernel_alt + p2_kernel_alt + plot_layout(nrow = 2, heights = c(0.5, 0.5))

p_kernel_alt

write_rds(p_kernel_alt, "plots/p_kernel_psychology_alt.rds")

ggsave("plots/p_kernel_psychology_alt.pdf", 
       plot = p_kernel_alt, 
       width = 6,
       height = 4,
       units = "in")

```

## Zoomed

```{r}

p1_kernel_alt_zoom <-
  ggplot(plot_data, aes(alpha, y = count, fill = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col(position = "stack") +
  geom_step(aes(y = density_kernel * total_n, group = 1), direction = "mid", size = 0.3) +
  #scale_fill_viridis_d(direction = -1, begin = 0.2, end = 0.65) +
  scale_fill_manual(values = cbp1) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.01),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  # scale_alpha_manual(values = c("3" = 0.35, "2" = 1, "1" = 1)) +
  theme_bw() +
  labs(x = "", # "Cronbach's &alpha;",
       y = "Count",
       fill = "") +
  ylim(0, 800) +
  theme(legend.position = "none",
        axis.title.x = element_markdown()) +
  coord_cartesian(xlim = c(.6725, .7175)) +
  annotate("text", 
           x = .70, 
           y = plot_data$count[plot_data$alpha == .70] + 120, 
           label = "Kernel\nsmoothing\n",
           size = 2.5) +
  annotate("segment", 
           x = .70, 
           xend = .70, 
           y = plot_data$count[plot_data$alpha == .70],  # observed counts
           yend = total_n * plot_data$density_kernel[plot_data$alpha == .70], # predicted counts
           arrow = arrow(ends = "both", 
                         angle = 45, 
                         length = unit(1.5,"mm"))) +
  annotate("text", 
           x = .69, 
           y = plot_data$count[plot_data$alpha == .70] + 120, 
           label = "Calliper\ntest\n",
           size = 2.5) +
  annotate("segment", 
           x = .69, 
           xend = .69, 
           y = plot_data$count[plot_data$alpha == .70],  # observed counts .70
           yend = plot_data$count[plot_data$alpha == .69], # observed counts .69
           arrow = arrow(ends = "both", 
                         angle = 45, 
                         length = unit(1.5,"mm")))

p2_kernel_alt_zoom <- 
  ggplot(plot_data, aes(alpha, residual_kernel * total_n, fill = type)) + 
  #geom_vline(xintercept = c(0.7, 0.8, 0.9), linetype = "dotted") +
  geom_col() +
  geom_hline(yintercept = 0, size = 0.2) +
  #scale_fill_manual(values = c("TRUE" = color_2, "FALSE" = color_1), guide = "none") +
  scale_fill_manual(values = cbp1) +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.01),
                     labels = label_number(accuracy = 0.01),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(from = -200, to = 200, by = 50),
                     labels = label_number(accuracy = 1),
                     minor_breaks = NULL) +
  theme_bw() +
  labs(x = "Cronbach's &alpha;",
       y = "Residual",
       fill = "") +
  theme(legend.position = "bottom",
        axis.title.x = element_markdown()) +
  coord_cartesian(xlim = c(.6725, .7175), ylim = c(-80, 145)) +
  annotate("text", 
           x = .70, 
           y = total_n * plot_data$residual_kernel[plot_data$alpha == .70] + 25, 
           label = "Kernel\nsmoothing\n",
           size = 2.5) +
  annotate("segment", 
           x = .70, 
           xend = .70, 
           y = 0,  
           yend = total_n * plot_data$residual_kernel[plot_data$alpha == .70], # predicted counts
           arrow = arrow(ends = "both", 
                         angle = 45, 
                         length = unit(1.5,"mm"))) +
  annotate("text", 
           x = .69, 
           y = total_n * plot_data$residual_kernel[plot_data$alpha == .70] + 25, 
           label = "Calliper\ntest\n",
           size = 2.5) +
  annotate("segment", 
           x = .69, 
           xend = .69, 
           y = total_n * plot_data$residual_kernel[plot_data$alpha == .69],
           yend = total_n * plot_data$residual_kernel[plot_data$alpha == .70], # residual .69
           arrow = arrow(ends = "both", 
                         angle = 45, 
                         length = unit(1.5,"mm")))

p_kernel_alt_zoom <- p1_kernel_alt_zoom + p2_kernel_alt_zoom + plot_layout(nrow = 2, heights = c(0.5, 0.5))

p_kernel_alt_zoom

ggsave("plots/p_kernel_method_comparison.pdf", 
       plot = p_kernel_alt_zoom, 
       width = 6,
       height = 4,
       units = "in")

```

## Combined

```{r}

(p1_kernel_alt + ggtitle("Full range")) +
  #(p1_kernel_alt_zoom + labs(title = "Subset around &alpha; = .70") + theme(plot.title = element_markdown())) +
  (p1_kernel_alt_zoom + ggtitle("Subset")) +
  p2_kernel_alt +
  p2_kernel_alt_zoom + 
  plot_layout(nrow = 2, ncol = 2,
              widths = c(0.6, 0.4, 0.6, 0.4),
              guides = "collect") &
  theme(legend.position = 'bottom') 

```

# Session info

```{r}

sessionInfo()

```
