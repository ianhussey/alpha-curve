
<!DOCTYPE html>
<html id="_htmlTag" lang="en">

<head><meta charset="utf-8" /><title>
	Power to detect differences between alternative treatments in comparative p...: EBSCOhost
</title>
	
<link rel="icon" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/ehost/favicon.ico" type="image/x-icon" />
<link rel="shortcut icon" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/ehost/favicon.ico" type="image/x-icon" />

	<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/ehost/master_bundle.css" media="All" />
<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/rtac.css" media="All" />
<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/common/abody.css" media="All" />
<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/selecteddatabasescontrol.css" media="All" />
<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/page/detail.css" media="All" />
<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/carousel.css" media="All" />
<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/bookcarousel.css" media="All" />
<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/emailprintdialog.css" media="All" />
<link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/print.css" media="Print" />
<!--[if lt IE 9]><link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/ie8.css" media="All" /><![endif]-->
<!--[if lt IE 8]><link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/ie7.css" media="All" /><![endif]-->
<!--[if lt IE 7]><link rel="stylesheet" type="text/css" href="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/css/_layout2/ie6.css" media="All" /><![endif]-->
<!--##EPCSS##-->
	
	<script>
var ep = {"version":"16.1.0.155","baseImagePath":"http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/","brandingPath":"http://imageserver.ebscohost.com/branding/","interfaceId":"ehost","cssLayout":2,"messages":{"Close":"Close","Loading":"Loading","show_this_area":"Show this area","hide_this_area":"Hide this area","column1-closed":"Show Left Column","column1-open":"Hide Left Column","column2-closed":"Show Right Column","column2-open":"Hide Right Column","sh_more":"Show More","sh_less":"Show Less","enter_email_address":"Please enter your e-mail address.","email_invalid_error":"Please provide a valid email address.","field_required":"This field is required.","your_subject_may_not_contain_html_markup":"Your subject may not contain HTML markup.","your_comments_may_not_contain_html_markup":"Your comments may not contain HTML markup.","err_sending_email":"Error Sending Email","your_message_may_not_contain_html_markup":"Your message may not contain HTML markup."},"clientData":{"googleTagManagerId":"GTM-NCMJP5","usrNo":0,"currentRecord":{"Db":"pdh","Tag":"AN","Term":"1989-26789-001"},"rtacView":"detail","rtacTimeout":30,"addThis":{"widgetUrl":"http://s7.addthis.com/js/250/addthis_widget.js#username=ebscohost","bookmarkUrl":"http://www.addthis.com/bookmark.php?v=250\u0026username=ebscohost"},"hoverPreviewLabelData":"{\"Abstract\":\"Abstract\",\"Date\":\"Date\",\"Source\":\"Source\",\"Subjects\":\"Subjects\",\"Title\":\"Title\",\"Citation\":\"Detail\",\"FullCitation\":\"Detailed Record\",\"AddToFolder\":\"Add to folder\",\"RemoveFromFolder\":\"Remove from folder\",\"FolderItem\":\"Folder Item\",\"AddExternalRecToFolder\":\"Add citation to Other Contents Folder\",\"RemoveExternalRecFromFolder\":\"Remove citation from Other Content Sources Folder\",\"AddToFolderTitle\":\"Add result to folder\",\"RemoveFromFolderTitle\":\"Remove result from folder\",\"AddRemoveToFolder\":\"Add/Remove \",\"AddRemoveToFolderTitle\":\"Add or remove from folders\",\"PublicationType\":\"Publication Type\",\"Database\":\"Database\",\"Duration\":\"Length (hours:minutes)\"}","plink":"http://search.ebscohost.com/login.aspx?direct=true\u0026db=pdh\u0026AN=1989-26789-001\u0026site=ehost-live"},"templates":{},"pageScripts":["bundled/jqueryplusui.js","bundled/underscore.js","bundled/_layout2/master.js","bundled/ehost/page/detail.js","bundled/buzzloader.js","bundled/buzzsessionsync.js","ep/selectdb.js","ep/widgets/epeditor.js","ckeditor/ckeditor.js","ckeditor/adapters/jquery.js","bundled/notesmodal.js","jquery/plugins/jquery.ba-bbq.js","ep/controller/realtimeavailabilitycontroller.js","ep/jqueryplugins/scrollto.js","ep/controller/concurrentaccesscontroller.js","ep/ep_readspeaker.js","ep/common/menubar.js","ep/googleclassroom/gc-boot.js"],"relativeRequestPath":"detail/detail","sid":"491cf965-6fb3-4046-b6ad-482934299d76@sessionmgr4001","vid":"0","existingReturnUrl":"","newReturnUrl":"/ehost/detail/detail?sid=491cf965-6fb3-4046-b6ad-482934299d76@sessionmgr4001\u0026vid=0\u0026hid=4106\u0026bdata=JnNpdGU9ZWhvc3QtbGl2ZQ==","locale":"en"}
</script>
<script src="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/javascript/bundled/ep_boot.js"></script>
<!--[if lt IE 9]>
<script src="http://smallcontent.ebsco-content.com/interfacefiles/16.1.0.155.1/javascript/html5shiv/html5.js"></script>
<![endif]-->
<script>

ep.boot(function() {
	ep.updateSearchMode();
	focusOnMainContent();
	
ep.util.url.updateHash("db=pdh&AN=1989-26789-001");

	ep.getInstance( { epId: 'ep.controller.page.CitationController' });
	ep.getScreenResolution();

},
null);
</script>
<!--##EPJS##-->
	
	
</head>
<body id="ctl00_ctl00__bodyTag" class="column1-open column2-open limited-scope no-skin detail ehost">
	
	

	<div id="epAjaxActive">Loading...</div>	
	<form method="post" action="detail?sid=491cf965-6fb3-4046-b6ad-482934299d76%40sessionmgr4001&amp;vid=0&amp;hid=4106&amp;bdata=JnNpdGU9ZWhvc3QtbGl2ZQ%3d%3d" id="aspnetForm">
<input type="hidden" name="AddToFolderClientIDs" id="AddToFolderClientIDs" value="" />
<input type="hidden" name="RelRequestPath" id="RelRequestPath" value="detail/detail" />
<input type="hidden" name="__sid" id="__sid" value="491cf965-6fb3-4046-b6ad-482934299d76@sessionmgr4001" />
<input type="hidden" name="__vid" id="__vid" value="0" />
<input type="hidden" name="__CUSTOMVIEWSTATE" id="__CUSTOMVIEWSTATE" value="H4sIAAAAAAAEAI1W227bRhCFadHXtg7SwC8tpDX6YgMmYceXWIVRwFZi1GibGLaR12DNHYpbL7nM7lKy+tR/6EP/rz/SziwpWfIl6IMo7mVmzpk5s8t/59bEWrga7e7vd/cOu2/eHKytB+1vP3IlBXdwCZ8rsO43LSCYWw/SNdE8gjna11K86IcBFDgxTxNhori14XGiVZUXu5EuoWD14HU9UDKXDkRkExyyQkf2VhZMgONSMci0degrxBAvxnHI7+JHaeWNgkyIYNHPU7jOfNYgwTcRLK01byJYbmzFeiu9n23dv674t37NZqkOtUCRVj9tnDvIe7oqXDC/vuCdBM1zER2stJd61vY8z+8MJNqIyI2QS6pNzl2USMed1EV7tafznBfiPc8h7L67iH+FPk9GcU8XzmilwNj4recdn3lTG/ca23p8WjmHftYaPyemX+VQONFufdq4Og0IPzIJJuXoBOHLBgSmOGc8cXIAAlM1SUbNoBOGL6eRlyKNUtdZCI//F8oLkZ5VSl3DnZsG2lkUnaUxqq8xTqvdoj3h8mb3aC8+/OV0q16br1WEgFskqjq3aVOQlq/4Qmc5/P5a5mBZj+TCUCMuk5a95Y7fcAudxXDFr/vlsd/asLV5sLv11Iap+ofjV4wfNHavzmQh2BUKVHHDLsFWytn24rXW6lqW4atLcEbCABhXipl6GcP8/dWFHoJhTpOMIXFMyDQFA0WC8G/ADQF1z5UDU3CqCHMGuKNSWuKV6Lzkpl4p7SjJtMvA8HLEdOVwESgWcJNkMetN7bWuEhIj6PShWeowYEpkUhgybbDNZjD5ZMLYvcUBd88BLI0WVQIxO1Eu01U/I1ML3r0s+pblfIQAU0XEyWtD50Yq6QjLM463J/i5gQZyoR2zVZrKROIWNWIlJTat1FRuKYTVxnnegJxwzso/0I+St4A2uPWGmrFC+sMMvbqhphzk2swQo7AJiZxbFEjMrtFxSZkuCIQZwIjBgKuKk/woqgfzRLabIo3pPC0D7MtJNA/9OVSIejJkA0sn5GQcs6ODR/EQFDBh+BBLbnTOuux3XWG+FYYZIGDO9qKRYSUYqQXb3O0e7f/z51/4d7gV+3YiOQBPMsyIk4mC2iPc8VwWSD2VxjpihUoYSIEr1klsenhcAQ/ep1xPcoc4sfRoknDVpBDFVuI5f0+T7FI8a/QwqsqYnY2lRf8J+fACnanBl7M9brrZENgF9xN4lnyu8GhgXOAdR0H6KNC6MbD9+zBLrbIVdj1JAlOA5lRPfyDVcpdWFzH7GdFhyrenoOIOA8qLH62HwG8fajlHv5HTUQ5CVvkXJD0O7UX9TLc+FnVlazhIUmJJyMFs3z/udd/SGFBUQKHJ+iGHSR1oEaWAtwI7z0tF5cL7q9a7LBAjtpTDYj6SbV1zg6mwsl/QjuSJs434ZLKfKfx5QpsX2Hzn788+TG4CPKjpJmObyRZ7vbO7x04uTrbrI5qMrD89sZ3FFntX5/YKc8s2r+51iSt31B+UBY+fXUy1OFS4iX0YJ+3x0jUkWSHpQ2lmcYTXzGp9q9F9OPmYqS+gb2YnJp8Y3mI5/OF4I4pQdWB+ZPbgaGfnYK8b51wWsf9GYiyKfhL/AUQdwDe9CQAA" />
<input type="hidden" name="__ScreenResolution" id="__ScreenResolution" value="" />
<input type="hidden" name="__VIEWSTATE" id="__VIEWSTATE" value="" />

		<!--[if lt IE 7]>	
		

<div class="ie6_req_block">
	<div class="ie6_req_text">
		IE6 users please note our browser requirements are changing! See  <a href="http://support.epnet.com/knowledge_base/detail.php?id=25" target="_blank" title="EBSCO's Support Site">EBSCO's Support Site</a>  for more information.
	</div>
</div>
		<![endif]-->
		
		<div id="outerContainer">
			<div id="innerContainer">
				
					
				
				
	
	
		

				
	
	

				
				<div id="header" class="clearfix" role="banner" >
					<div id="pageInstruction" tabindex="-1" class="hidden">citation_instruction</div><p tabindex="0" class="hidden"><a href="javascript:openWideTip('http://support.ebsco.com/help/?int=ehost&lang=en&feature_id=access&TOC_ID=Always&SI=0&BU=0&GU=1&PS=0&ver=&dbs=pdh')">Accessibility Information and Tips</a> Revised Date: 07/2015</p>
					<h1 title="Power to detect differences between alternative treatments in comparative psychotherapy outcome research" class="hidden">Power to detect differences between alternative treatments in comparative psychotherapy outcome research</h1>
					
					
	<div class="customerLogo"><a href="javascript:__doPostBack('ctl00$ctl00$FindField$customerLogo');"><img src="http://www.tilburguniversity.edu/static/uvtpresentation/images/framework/logo.jpg" alt="Library Logo" /></a></div>
	

					
				</div>
					<div id="mainContentArea" >
						<div id="content" role="main" class="text-normal" >
							
	
	<div class="content-header" >
	 

	</div>
	
	
	

	
	<div id="ToolPanelContent" class="bg-p2" >
		<div class="wrapper clearfix" >
		</div>
		<a  href="#" title="Close Panel" class="close-panel"></a>
	</div>

	<!-- If citation is being displayed it will be rendered inside this placeholder.
		 If citation is not being displayed, full text will be rendered in this placeholder. -->
	<div class="ft-translation hidden"><label for="transLanguage">Translate Full Text:</label></div><div class="ft-translation"><a name="Translate"> </a><select id="transLanguage" name="transLanguage" title="Choose Language"><option value="" selected="selected">Choose Language</option><option value="Arabic">الإنجليزية/العربية</option><option value="Bulgarian">английски език/български</option><option value="SimplifiedChinese">英语/简体中文</option><option value="TraditionalChinese">英語/繁體中文</option><option value="Czech">angličtina/čeština</option><option value="Danish">Engelsk/dansk</option><option value="Dutch">Engels/Nederlands</option><option value="French">Anglais/Français</option><option value="German">Englisch/Deutsch</option><option value="Greek">Αγγλικά/Ελληνικά</option><option value="Hausa">English/Hausa</option><option value="Hebrew">אנגלית/עברית</option><option value="Hindi">अंग्रेज़ी/हिंदी</option><option value="Hungarian">angol/magyar</option><option value="Indonesian">Inggris/bahasa Indonesia</option><option value="Italian">Inglesi/Italiano</option><option value="Japanese">英語/日本語</option><option value="Korean">영어/한국어</option><option value="Norwegian">Engelsk/Norsk</option><option value="Persian">انگليسی/فارسی</option><option value="Polish">angielski/polski</option><option value="Portuguese">Inglés/Português</option><option value="Pashto">English/Pashto</option><option value="Romanian">Engleză/română</option><option value="Russian">Английский/Русский</option><option value="Spanish">Inglés/Español</option><option value="Serbian">English/Serbian</option><option value="Swedish">Engelska/svenska</option><option value="Thai">อังกฤษ/ไทย</option><option value="Turkish">İngilizce/Türk</option><option value="Ukranian">Англійська/Українська</option><option value="Urdu">انگریزی/اردو</option></select>&nbsp;<input type="button" id="translateBtn" class="translate" value="Translate" title="Translate" /><input type="button" id="translateOriginal" class="translate" value="Back to English" title="Back to English" /></div><div id="translationProgressContainer" style="display: none;"><span>Translation in Progress:</span><div class="translationProgressBar"><div id="translationProgressBar" class="bg-p1"> </div></div></div><div id="translationErrorContainer" class="medium-normal translation-message" style="display: none;"> </div><div id="translationDisclaimerContainer" style="display: none;"><div class="translation-message"><span class="medium-bold"><span class="txt-red" id="translationDisclaimerLine1"> </span></span><span class="medium-normal" id="translationDisclaimerLine2"> </span><span class="medium-bold" id="translationDisclaimerLine3"> </span><div class="medium-normal">Translations powered by Language Weaver Service<br /></div></div></div><script type="text/javascript">
				ep.getInstance("ep.controller.control.translation");
				ep.require( "common/translation.css" );
			</script><dl class="short-citation" data-auto="short_citation" xmlns:viewExtensions="http://www.ebscohost.com/schema/viewExtensions"><dt class="medium-bold" data-auto="short_citation_title_label">Title: </dt><dd class="medium-normal" data-auto="short_citation_title">Power to detect differences between alternative treatments in comparative psychotherapy outcome research.<span class="updated-short-citation"> By: Kazdin, Alan E., Bass, Debra, Journal of Consulting and Clinical Psychology, 0022006X, 19890201,  Vol. 57,  Issue 1</span></dd><dt class="medium-bold" data-auto="short_citation_long_dbname_label">Database: </dt><dd class="medium-normal" data-auto="short_citation_long_dbname">PsycARTICLES</dd></dl><div class="full-text-container border" data-auto="fulltext_container" xmlns:viewExtensions="http://www.ebscohost.com/schema/viewExtensions"><h2 class="hidden" data-auto="fulltext_title_hidden">HTML Full Text</h2><h2 data-auto="local_abody_title" class="ft-title border color-p4 bar4">Power to Detect Differences Between Alternative Treatments in Comparative Psychotherapy Outcome Research</h2><div class="html-ft-toc" data-auto="html_toc"><h3 class="small-bold" id="toc" data-auto="html_toc_title">Contents</h3><ol data-auto="html_toc_list"><li class="link-medium" data-auto="html_toc_list_item"><a data-auto="ep_link" href="#ccp-57-1-138-ID0ECCAA" id="hd_ccp-57-1-138-ID0ECCAA" title="Method">Method</a></li><li data-auto="html_toc_list_item" class="link-medium html-toc-hd1"><a data-auto="ep_link" href="#ccp-57-1-138-ID0ECCCAA" id="hd1_ccp-57-1-138-ID0ECCCAA" title="Studies of Interest">Studies of Interest</a></li><li data-auto="html_toc_list_item" class="link-medium html-toc-hd1"><a data-auto="ep_link" href="#ccp-57-1-138-ID0EBCCAA" id="hd1_ccp-57-1-138-ID0EBCCAA" title="Comparisons of Interest">Comparisons of Interest</a></li><li data-auto="html_toc_list_item" class="link-medium html-toc-hd1"><a data-auto="ep_link" href="#ccp-57-1-138-ID0EACCAA" id="hd1_ccp-57-1-138-ID0EACCAA" title="Measure and Calculation of Effect Size">Measure and Calculation of Effect Size</a></li><li class="link-medium" data-auto="html_toc_list_item"><a data-auto="ep_link" href="#ccp-57-1-138-ID0EBCAA" id="hd_ccp-57-1-138-ID0EBCAA" title="Results">Results</a></li><li data-auto="html_toc_list_item" class="link-medium html-toc-hd1"><a data-auto="ep_link" href="#ccp-57-1-138-ID0EDBCAA" id="hd1_ccp-57-1-138-ID0EDBCAA" title="Descriptive Characteristics">Descriptive Characteristics</a></li><li data-auto="html_toc_list_item" class="link-medium html-toc-hd1"><a data-auto="ep_link" href="#ccp-57-1-138-ID0ECBCAA" id="hd1_ccp-57-1-138-ID0ECBCAA" title="Sample Sizes and Estimates of Effect Size">Sample Sizes and Estimates of Effect Size</a></li><li data-auto="html_toc_list_item" class="link-medium html-toc-hd1"><a data-auto="ep_link" href="#ccp-57-1-138-ID0EBBCAA" id="hd1_ccp-57-1-138-ID0EBBCAA" title="Estimated Power">Estimated Power</a></li><li data-auto="html_toc_list_item" class="link-medium html-toc-hd1"><a data-auto="ep_link" href="#ccp-57-1-138-ID0EABCAA" id="hd1_ccp-57-1-138-ID0EABCAA" title="Sample Sizes for Psychotherapy Research">Sample Sizes for Psychotherapy Research</a></li><li class="link-medium" data-auto="html_toc_list_item"><a data-auto="ep_link" href="#ccp-57-1-138-ID0EACAA" id="hd_ccp-57-1-138-ID0EACAA" title="Discussion">Discussion</a></li><li class="link-medium" data-auto="html_toc_list_item"><a data-auto="ep_link" href="#ccp-57-1-138-ID0EAA" id="hd_ccp-57-1-138-ID0EAA" title="Footnotes">Footnotes</a></li><li class="link-medium" data-auto="html_toc_list_item"><a data-auto="ep_link" href="#ccp-57-1-138-ID0E0VB0ABAA" id="hd_ccp-57-1-138-ID0E0VB0ABAA" title="References">References</a></li></ol></div><section id="TextToSpeech" class="full-text-content textToSpeechDataContainer" data-auto="text_to_speech" data-text-to-speech-cache-key="pdh_1989-26789-001" data-text-to-speech-title="Power to detect differences between alternative treatments in comparative psychotherapy outcome research." data-text-to-speech-author="Kazdin, Alan E." data-text-to-speech-additional-filename="19890201"><span id="textToSpeechPlaceholder"> </span><div class="center" xmlns:Translation="urn:EBSCO-Translation"><strong>By: Alan E. Kazdin</strong><br /><em>Western Psychiatric Institute and Clinic</em>;<br /><em>University of Pittsburgh School of Medicine</em>;<br /><strong>Debra Bass</strong><br /><em>Western Psychiatric Institute and Clinic</em>;<br /><em>University of Pittsburgh School of Medicine</em></div><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><strong>Acknowledgement: </strong>Completion of this article was facilitated by Research Scientist Development Award MH00353 and by Grant MH35408 from the National Institute of Mental Health. We are extremely grateful to Jacob Cohen, Larry V. Hedges, and Kenneth I. Howard. Special thanks are also extended to Helena C. Kraemer, who provided comments and guidance on prior drafts.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">In psychotherapy research, comparative outcome studies address the question of which of two or more techniques is the most effective for a particular clinical problem and patient population. Often the constituent treatments reflect conflicting conceptual views about the nature of dysfunction, the focus of treatment, and the techniques required to produce change. Consequently, comparative studies generate tremendous interest (see <a href="#c22">Heimberg &amp; Becker, 1984</a>; <a href="#c25">Kazdin, 1986</a>; <a href="#c34">Lambert, Shapiro, &amp; Bergin, 1986</a>; <a href="#c36">Luborsky, Singer, &amp; Luborsky, 1975</a>; <a href="#c41">Rachman &amp; Wilson, 1980</a>; <a href="#c49">Stiles, Shapiro, &amp; Elliott, 1986</a>).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Outcome evidence on the relative effectiveness of alternative treatments has been evaluated extensively. Conclusions have been drawn from individual comparative outcome investigations (e.g., <a href="#c46">Sloane, Staples, Cristol, Yorkston, &amp; Whipple, 1975</a>), box-score (e.g., <a href="#c36">Luborsky et al., 1975</a>) and narrative reviews (e.g., <a href="#c28">Kazdin &amp; Wilson, 1978</a>; <a href="#c34">Lambert et al., 1986</a>; <a href="#c41">Rachman &amp; Wilson, 1980</a>), and meta-analyses (see <a href="#c2">Brown, 1987</a>). Although individual studies and large-scale reviews occasionally argue for the superiority of one technique over another, evaluations of the literature usually suggest that treatments tend not to differ or at least not to differ very much in the outcomes they produce.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The absence of clear outcome differences between alternative treatments has served as an important point of departure regarding the nature of therapy and the processes that account for change (see <a href="#c49">Stiles et al., 1986</a>). As a prominent example, <a href="#c17">Frank (1982)</a> suggested that therapeutic change results from several features that are common among different techniques. Thus, no outcome differences between treatments might be expected given their common ingredients. This view has been bolstered in part by the recognition that different techniques often appear more diverse in theory than they do in clinical practice (e.g., <a href="#c30">Klein, Dittmann, Parloff, &amp; Gill, 1969</a>; <a href="#c46">Sloane et al., 1975</a>). Common ingredients, particularly the special relationship between client and therapist and the provision of support, empathy, and concern, are pervasive among alternative techniques (<a href="#c52">Waterhouse &amp; Strupp, 1984</a>).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Current estimates suggest that well over 400 psychotherapy techniques are in use for adults (Karasu, personal communication, March 1, 1985) and that over 230 techniques are in use for children (<a href="#c26">Kazdin, 1988</a>). If we assume that many of these techniques are effective in producing therapeutic change, it is difficult to conceive that they vary in effectiveness or operate through different therapeutic processes. Yet, this assumption is not tantamount to staling that the results from viable treatment contenders for a given clinical problem will be similar. Whether treatment outcomes differ can only be evaluated empirically. The finding that treatments do not differ in many, if not most, tests may mean that treatments are approximately equal in their effects. Yet, it is important to know if the studies are, as a rule, designed to detect outcome differences. When two or more active interventions are expected to produce change, the investigation must be sufficiently sensitive to detect what could prove to be relatively small differences.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">A critical research issue is the extent to which an investigation can detect differences between groups when differences exist within the population. This notion is referred to as <em>statistical power</em> and reflects the probability that the test will lead to rejection of the null hypothesis.<a id="b-fn1"> </a><sup><a href="#fn1" /></sup>
Power is a function of the criterion for statistical significance (alpha), sample size (<em>N</em>), and the difference that exists between groups (effect size).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Although power is an issue in virtually all research, it raises special issues in studies where two or more conditions (groups) are not significantly different (<a href="#c13">Fagley, 1985</a>; <a href="#c18">Freiman, Chalmers. Smith, &amp; Kuebler, 1978</a>; <a href="#c24">Kazdin, 1980</a>). The absence of significant differences can contribute to knowledge under a variety of circumstances. However, an essential precondition is that the investigation be sufficiently powerful to detect meaningful differences. In the vast majority of psychotherapy outcome studies that have contrasted two or more treatments, the power may have been relatively weak due to small samples sizes.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">There are many reasons to suspect that outcome studies as a general rule provide weak tests. Over 25 years ago, <a href="#c6">Cohen (1962)</a> examined clinical research published in the <em>Journal of Abnormal and Social Psychology</em> for a 1-year period (1960). Over 2,000 statistical tests were identified (from 70 articles) that were considered to reflect direct tests of the hypotheses. To evaluate power, Cohen examined different effect sizes, that is, the magnitude of the differences between alternative groups based on standard deviation units. Cohen distinguished three levels of effect sizes (small = .25, medium = .50, and large = 1.00) and evaluated the power of published studies to detect differences at these levels, assuming alpha = .05 and using nondirectional (two-tailed) tests.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The results indicated that power was generally weak for detecting differences equivalent to small and medium effect sizes. For example, the mean power of studies to detect differences reflecting small and medium effect sizes was. 18 and .48, respectively. This means that, on the average, studies had slightly less than a 1 in 5 chance to detect small effect sizes and less than a 1 in 2 chance to detect medium effect sizes. These levels are considerably below the recommended level of power, .80 (4 in 5 chance).<a id="b-fn2"> </a><sup><a href="#fn2" /></sup>
Cohen concluded that the power of the studies was weak and that sample sizes in future studies should routinely be increased (see also <a href="#c9">Cohen, 1977</a>).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">A more recent analysis examined if the situation has improved since Cohen’s earlier portrayal. <a href="#c43">Rossi, Rossi, and Cottrill (1984)</a> sampled research from the <em>Journal of Personality and Social Psychology</em> and the <em>Journal of Abnormal Psychology,</em> journals that are descendants of the publication Cohen analyzed. The data were obtained from 142 articles in the 1982 volume of each journal. Rossi et al. found that 3%, 26%, and 69% of the studies in 1982 had power above .80 for detecting small, medium, and large effects, respectively. This compared with parallel data from <a href="#c6">Cohen (1962)</a> of 0%, 9%, and 79%, respectively. Although slight increases in power were evident for detecting small and medium effects, the vast majority of studies were quite weak with regard to detecting such effects.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The applicability of these findings to psychotherapy outcome research might be challenged. The surveys of <a href="#c6">Cohen (1962)</a> and <a href="#c43">Rossi et al. (1984)</a> covered only a 1-year period, sampled a small number of journals, and encompassed diverse areas of research within clinical and social psychology. Perhaps, more to the point, the surveys did not focus on psychotherapy outcome exclusively or primarily. Yet, the characteristics of psychotherapy outcome studies may make the conclusions even more applicable.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">To begin with, small sample sizes may be dictated in part by the subject matter due to difficulties in recruiting, treating, and retaining large samples of homogeneous subjects (<a href="#c31">Kraemer, 1981</a>). In contemporary outcome research, studies typically include 20 or fewer subjects per group (e.g., <a href="#c10">Cross, Sheehan, &amp; Khan, 1982</a>; <a href="#c11">DiLoreto, 1971</a>; <a href="#c35">Liberman &amp; Eckman, 1981</a>; <a href="#c44">Rush, Beck, Kovacs, &amp; Hollon, 1977</a>). Indeed, it is not difficult to find studies comparing alternative treatment and control conditions in which the sample sizes are 10 or fewer cases per condition (e.g., <a href="#c16">Forman, 1980</a>; <a href="#c53">Yu, Harris, Solovitz, &amp; Franklin, 1986</a>). Inadequate levels of power could be a rival explanation for the absence of treatment differences.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">A second problem of psychotherapy research is the loss of subjects over time. Apart from the possible selection biases that attrition can introduce, sample sizes (and power) may be markedly reduced by the end of treatment and by the follow-up assessment (<a href="#c20">Garfield, 1980</a>). The toll of attrition on the design is often high. In some treatment programs, between 40% and 50% of subjects may drop out of treatment (e.g., <a href="#c15">Fleischman, 1981</a>; <a href="#c38">Patterson, 1974</a>; <a href="#c50">Viale-Val, Rosenthal, Curtiss, &amp; Marohn, 1984</a>). In one large-scale comparative outcome study, almost 90% of the cases (396 of 450) that completed treatment were lost at follow-up 1 year later (<a href="#c14">Feldman, Caplinger, &amp; Wodarski, 1983</a>). Thus, in psychotherapy outcome studies, sample size and power may weaken considerably over time. If the conclusion of no differences between treatments is not evident at posttreatment, it may well be reached at follow-up.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">One may be able to discern from psychotherapy research the approximate effect sizes for classes of comparisons such as treatment versus no treatment and treatment versus treatment. Indeed, such effect sizes have often been examined in the context of meta-analysis. Effect sizes obtained after experiments are completed provide an estimate of population effect sizes (<a href="#c8">Cohen, 1973</a>). It is important to examine effect sizes for comparisons of alternative therapy techniques, not only to determine the magnitude of the differences with which we may be working, but also to interpret studies in which critical tests of treatment are provided and few or no differences emerge.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">From the published research, one can estimate the power of studies to detect differences of the magnitudes that emerge for comparisons of alternative treatment conditions. There is, of course, the bias that derives from consulting only published studies. Such studies may be more prone to yield significant effects, whereas those that did not yield such effects may be unpublished and relegated to the investigator’s file drawer (<a href="#c42">Rosenthal, 1979</a>). However, comparative outcome studies with few or no differences are often published (e.g., <a href="#c46">Sloane et al., 1975</a>). The reasons include the keen interest in the comparisons in their own right, the likely differences between the treatments and the no-treatment or waiting-list control condition, and the evaluation of therapeutic processes common to alternative techniques.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">In the present article, we examine the power of treatment outcome studies to detect differences when alternative treatments are compared. The question is important because the general absence of differences between two or more treatments tested in a given study may be viewed differently, depending on whether the experimental tests have adequate power. It might well be that the outcome evidence argues generally for the absence of major treatment differences. To argue this position requires some assurance that the tests comparing different treatments are sufficiently powerful. The question can be addressed by examining the effect sizes of current outcome studies to detect differences between alternative treatment conditions and the sample sizes that are used.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">In meta-analyses of psychotherapy, the usual goal is to compare treatment against a control group and to draw conclusions about the magnitude of effect sizes for specific techniques (e.g., behavior therapy vs. cognitive therapy). A related goal in the present article was to examine the power of psychotherapy studies to detect differences when two or more treatments are included. However, the specific techniques and the direction of their differences in relation to each other were not of interest. The objective was to examine the power to detect differences with different types or classes of comparisons.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The power of psychotherapy studies was examined by estimating effect sizes from findings of psychotherapy outcome studies for the comparisons of interest. Effect sizes and power were estimated for comparisons at posttreatment and follow-up because of the changes in sample sizes (attrition) over the course of therapy studies and the different and occasionally diametrically opposed outcomes that alternative treatments can produce at different points in time (see <a href="#c26">Kazdin, 1988</a>). Treatment studies were surveyed from nine journals over a 3-year period. Statistical tests were examined from the psychotherapy studies to estimate their power to detect differences where they exist in comparing alternative treatment conditions.</p><a id="ccp-57-1-138-ID0ECCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><span class="medium-bold" xmlns:Translation="urn:EBSCO-Translation"><a data-auto="ep_link" href="#toc" id="hd_toc_26" title="Method">Method</a></span><br xmlns:Translation="urn:EBSCO-Translation" /><a id="ccp-57-1-138-ID0ECCCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><h4 xmlns:Translation="urn:EBSCO-Translation">Studies of Interest</h4><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Psychotherapy outcome studies were selected for the present evaluation. <em>Psychotherapy</em> was defined to include interventions designed to decrease distress, psychological symptoms, and maladaptive behavior or designed to improve adaptive and prosocial functioning through the use of interpersonal interaction, counseling, or activities following a specific treatment plan (see <a href="#c20">Garfield, 1980</a>; <a href="#c51">Walrond-Skinner, 1986</a>). Excluded from the definition were interventions using medication as a form of treatment or interventions directed singularly at educational goals (e.g., reading improvement). <em>Outcome investigations</em> referred to studies designed to measure some facet of psychological adjustment or functioning after treatment was completed (posttreatment). At least two groups or conditions were required for the study to be included. The groups could include any combination of treatment and control conditions. Although primary interest was in studies comparing two or more treatments, all psychotherapy outcome studies were included if there were at least two groups. This inclusion criterion was adopted to permit evaluation of power for the different comparisons (one treatment vs. another, treatment vs. no-treatment).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">To provide a sample of psychotherapy outcome research, nine journals were studied for a 3-year period (1984-1986). Four journals were selected because they were the most frequent contributors to meta-analyses of psychotherapy outcome research (<a href="#c45">Shapiro &amp; Shapiro, 1982</a>; <a href="#c47">Smith, Glass, &amp; Miller, 1980</a>). The journals included the <em>Journal of Consulting and Clinical Psychology,</em> the <em>Journal of Counseling Psychology, Behavior Therapy,</em> and <em>Behaviour Research and Therapy</em>. In addition, five other journals were selected because they reflect disciplines (psychiatry) in which treatment outcome research is published, they are often viewed as publication outlets for clinical trials, or their publication domain explicitly delineates psychotherapy research. Thus, these latter journals were selected largely on the basis of face validity, that is, because they include therapy research and appear by virtue of publication domain to be a primary outlet. For this group, five journals were selected: <em>Archives of General Psychiatry, American Journal of Psychiatry, Psychotherapy: Theory, Research and Practice, British Journal of Psychiatry,</em> and <em>British Journal of Clinical Psychology</em>. From the different journals for a 3-year period, 120 psychotherapy outcome studies were identified. Of these, 85 (70.8%) provided sufficient statistical information to compute effect sizes.<a id="b-fn3"> </a><sup><a href="#fn3" /></sup></p><a id="ccp-57-1-138-ID0EBCCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><h4 xmlns:Translation="urn:EBSCO-Translation">Comparisons of Interest</h4><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">To evaluate the statistical power of these psychotherapy studies, three types of comparisons were made: (a) comparison of each treatment with the other treatments included in the study, (b) comparison of treatment with a no-treatment control condition, and (c) comparison of treatment with an active, nonspecific (attention placebo) control condition. Of primary interest was the first comparison that addresses the question of the effect size and power when alternative treatments are compared. The comparisons involving treatment and alternative control conditions provide important baseline data regarding the power for detecting different types of effects in outcome research.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><em>Treatments</em> consisted of alternative psychotherapy techniques given the definition noted previously. <em>No-treatment control</em> referred to any group from which treatment was withheld during the pre- to posttreatment interval for the treatment group. <em>Active control</em> referred to groups in which an attention placebo or discussion control procedure was used to control for such factors as meeting with a therapist and attending sessions.<a id="b-fn4"> </a><sup><a href="#fn4" /></sup></p><a id="ccp-57-1-138-ID0EACCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><h4 xmlns:Translation="urn:EBSCO-Translation">Measure and Calculation of Effect Size</h4><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Within each study, an effect size was calculated between each pair of groups on each outcome measure. Effect size (ES) was defined as 
(<em>m</em>1 − <em>m</em>2 
)/<em>s</em>
where <em>m</em>1 and <em>m</em>2 refer to two group means (treatment or control) and <em>s</em> is the pooled within-group standard deviation.<a id="b-fn5"> </a><sup><a href="#fn5" /></sup>
Each ES was classified as coming from a comparison of two treatments, of treatment versus no treatment, or of treatment versus an active control. Also, each ES was classified as evaluated at posttreatment or at follow-up. If multiple follow-up assessments were reported, only the last (longest duration) assessment was considered. Thus, six types of ESs might have been derived from a single study. Within a study, multiple values of each effect size might have been obtained if there were several outcome measures. The ESs of each type within a study were averaged, so that each study contributed no more than one mean ES per comparison of interest.<a id="b-fn6"> </a><sup><a href="#fn6" /></sup></p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Of central interest was the case in which two or more treatments (<em>T</em>1, <em>T</em>2, …, <em>T</em><em>k</em>) were compared. In these cases, 
<em>T</em>1 
and 
<em>T</em>2 
were each separate treatments (e.g., cognitive therapy, behavior therapy). The specific conditions that constituted 
<em>T</em>1 
and 
<em>T</em>2 
within a given study or across studies were not of interest. There was no interest, for the present purposes, in drawing conclusions about the relative merits of alternative psychotherapy techniques. Across all studies, the identity of the treatment conditions designated as 
<em>T</em>1 
or 
<em>T</em>2 
varied. The goal was to evaluate the power of comparative studies to detect differences between alternative treatments. Consequently, in computing ESs for treatment versus treatment comparisons, the absolute value of the ES 
(|<em>m</em>1 − <em>m</em>2 |/<em>s</em>)
was calculated. Thus, the mean ES for a study with two treatments would be the mean of the absolute value differences between each of these treatments for each of the outcome measures. Similarly, for comparative purposes, the absolute magnitude of the differences was used to compute ESs between treatment and control conditions<a id="b-fn7"> </a><sup><a href="#fn7" /></sup>
Effect sizes were calculated from the means and standard deviations reported in the studies. When this information was unavailable, ESs were calculated from other reported statistics. Techniques for estimating ESs from other data sources are described elsewhere (<a href="#c47">Smith et al., 1980</a>).</p><a id="ccp-57-1-138-ID0EBCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><span class="medium-bold" xmlns:Translation="urn:EBSCO-Translation"><a data-auto="ep_link" href="#toc" id="hd_toc_41" title="Results">Results</a></span><br xmlns:Translation="urn:EBSCO-Translation" /><a id="ccp-57-1-138-ID0EDBCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><h4 xmlns:Translation="urn:EBSCO-Translation">Descriptive Characteristics</h4><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">From the nine journals, 85 psychotherapy outcome studies were used to compute effect sizes and to estimate power. Two of the journals (<em>American Journal of Psychiatry, Psychotherapy: Theory, Research and Practice</em>) yielded no studies for the present analysis. Effect sizes for the comparisons of interest were computed for each of the measures within a study. A total of 2,501 ESs were computed: 1,752 at posttreatment and 749 at follow-up. However, each study could yield only one ES for each of the comparisons of interest (e.g., treatment vs. no treatment) at posttreatment and follow-up. Thus, the number of ESs varied depending on the groups and assessment periods included in the study.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><a href="#tbl1">Table 1</a> presents the number of studies available from each journal, the sample sizes for the studies, the group composition, the types and time points of comparisons, and the study length. The journals are presented separately in this initial table for descriptive purposes. Individual journals were not of interest and, hence, are combined in subsequent analyses. The table details information relevant to the evaluation of power but also portrays several basic characteristics of psychotherapy outcome studies.<br /><br /><a id="tbl1"> </a><span class="centered"><img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/c6c7cb8361257bddb6a413451405c2ac/571c2fef/pdh/ccp/ccp-57-1-138-tbl1a.gif" alt="ccp-57-1-138-tbl1a.gif" title=" " /><em> </em></span></p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The mean sample size (<em>N</em>) for all studies was 53 subjects 
(<em>SD</em> = 39.2)
; the mean number of groups was 3 
(<em>SD</em> = 1.2)
. All 85 studies included at least one treatment group, given that this was a selection criterion for inclusion; 75 (88.2%) of the studies included two or more treatment conditions; 40 (47.1%) of the studies included a no-treatment or waiting-list control condition. Only 8 (9.4%) studies included an active control (e.g., attention-placebo) condition. In terms of outcome evaluation all studies included posttreatment and 67.1% of the studies included a follow-up assessment.<a id="b-fn8"> </a><sup><a href="#fn8" /></sup>
The mean duration of the longest follow-up in the studies was 8.0 months 
(<em>SD</em> = 7.5)
.</p><a id="ccp-57-1-138-ID0ECBCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><h4 xmlns:Translation="urn:EBSCO-Translation">Sample Sizes and Estimates of Effect Size</h4><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><a href="#tbl2">Table 2</a> summarizes the sample sizes observed from the studies surveyed. As noted in this table and in the others that follow, medians, 25th, and 75th percentiles are presented. The median (50th percentile) is presented as a measure of central tendency uninfluenced by extreme data points (outliers) that might affect both the mean and the standard deviation. The 25th and 75th percentiles are presented as the interval that captures 50% of the studies about that median. The discussion focuses on means to make the present comments parellel with other evaluations in which effect sizes of psychotherapy research have been examined.<br /><br /><a id="tbl2"> </a><span class="centered"><img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/3c0ecece0ae1312abbfc7e3b2093f2b9/571c2fef/pdh/ccp/ccp-57-1-138-tbl2a.gif" alt="ccp-57-1-138-tbl2a.gif" title=" " /><em> </em></span></p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">As is evident in the table, the sample sizes were quite similar across treatment and control groups. Consideration of the data pooled across groups revealed that the mean group sizes at posttreatment and follow-up were 16.1 and 15.3, respectively. Examination of the 75th percentile conveyed that three fourths of the studies included fewer than 20 subjects per group.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><a href="#tbl3">Table 3</a> presents estimated effect sizes for the comparisons of interest. As a potential guideline for the interpretation of the data, it is useful to bear in mind <a href="#c9">Cohen’s (1977)</a> classification of small, medium, and large ESs at .20, .50, and .80.<a id="b-fn9"> </a><sup><a href="#fn9" /></sup>
When two or more treatments were compared with each other, the mean absolute ESs at posttreatment and follow-up were .50 and .47, respectively. These fall within the range of medium ESs. The mean absolute ES across all outcome studies comparing treatment versus no treatment was .85 at posttreatment and .89 at follow-up. These ESs fall within the range of large ESs. Few studies (8 at posttreatment, 5 at follow-up) were available that compared treatment versus active control conditions. The mean ES for this comparison was .38 at posttreatment and .32 at follow-up, both between small and medium ESs.<a id="b-fn10"> </a><sup><a href="#fn10" /></sup><br /><br /><a id="tbl3"> </a><span class="centered"><img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/a20be50a834566021be4f1aeba3c1531/571c2fef/pdh/ccp/ccp-57-1-138-tbl3a.gif" alt="ccp-57-1-138-tbl3a.gif" title=" " /><em> </em></span></p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The range of ESs obtained for the comparison of interest are illustrated in <a href="#fig1">Figure 1</a>. This figure conveys the median ES and the 25th and 75th percentiles, a range that includes 50% of the studies for the comparison of interest. The data convey clearly that the comparisons of alternative treatments span the small-to-medium range. In contrast, the ESs for treatment versus no treatment are in the medium-to-large range.<br /><br /><a id="fig1"> </a><span class="centered"><img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/a4d06d5f967887ba005294c6b4d04927/571c2fef/pdh/ccp/ccp-57-1-138-fig1a.gif" alt="ccp-57-1-138-fig1a.gif" title="Figure 1. Effect sizes (ESs) obtained from comparisons of treatment (T) with another treatment or with no treatment (NT) separately for posttreatment (P) and follow-up (FU). The column for each comparison reflects the range of ESs from the 25th to the 75th percentiles; the horizontal line within each column reflects the median ES" /><em>Figure 1. Effect sizes (ESs) obtained from comparisons of treatment (T) with another treatment or with no treatment (NT) separately for posttreatment (P) and follow-up (FU). The column for each comparison reflects the range of ESs from the 25th to the 75th percentiles; the horizontal line within each column reflects the median ES</em></span></p><a id="ccp-57-1-138-ID0EBBCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><h4 xmlns:Translation="urn:EBSCO-Translation">Estimated Power</h4><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">If ESs fall within the ranges noted previously, one can estimate the extent to which studies, as currently designed, are likely to be powerful enough to detect significant differences between alternative types of comparisons. Based on sample sizes and estimated ESs, power can be estimated from the tables provided by <a href="#c9">Cohen (1977)</a>. For the purpose of identifying power, alpha was set at .05 for two-tailed tests of significance. Also, the mean group size (<em>n</em>) was used in cases in which groups were unequal in size or individual group size could not be determined (<a href="#c9">Cohen, 1977</a>). The use of an arithmetic mean for the groups facilitates the use of power tables. Assuming equal group sizes also maximizes the power for the sample size of a study and, consequently, provides an optimal level of power for the study given the fixed sample size. Power functions are nonlinear. Because the arithmetic average (mean) does not weight the different levels appropriately, median levels of power are discussed. The median estimated levels of power for the different comparisons of interest, accompanied by 25th and 75th percentiles, are presented in <a href="#tbl4">Table 4</a>.<br /><br /><a id="tbl4"> </a><span class="centered"><img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/a179be4bf8561c1c04ee5e8f6cadce3f/571c2fef/pdh/ccp/ccp-57-1-138-tbl4a.gif" alt="ccp-57-1-138-tbl4a.gif" title=" " /><em> </em></span></p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The primary question concerned the power to detect differences when two or more alternative treatments are compared. As noted in <a href="#tbl4">Table 4</a>, the power to detect differences for this type of comparison yielded a median of .74 at posttreatment and of .63 at follow-up. Thus, the median chance of a study to detect a difference at posttreatment and at follow-up is about 7 in 10 and 3 in 5, respectively. For individual studies comparing two or more treatments, 45.3% (34 of 75) and 28.6% (12 of 42), respectively, met the criterion of power ≥ .80 needed to detect differences between treatment groups at posttreatment and follow-up. The majority (54.7% and 71.4%) of studies that compared alternative treatments did not meet the recommended level of power.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The table indicates relatively strong power for the test of treatment versus no treatment. Median power was estimated at .995 at posttreatment and follow-up for this comparison. Using .80 as a criterion for adequate power, outcome studies generally are sufficiently powerful to detect differences between treatment versus no treatment. As for the individual outcome studies, 82.5% (33 of 40) and 90.0% (9 of 10) met the criterion of power ≥ .80 for the comparison of treatment versus no treatment at posttreatment and follow-up, respectively.</p><a id="ccp-57-1-138-ID0EABCAA" xmlns:Translation="urn:EBSCO-Translation"> </a><h4 xmlns:Translation="urn:EBSCO-Translation">Sample Sizes for Psychotherapy Research</h4><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Based on data obtained in the present survey, more specific comments can be made about requisite samples sizes when alternative forms of psychotherapy are compared. Assume for a moment that an investigator wishes to compare two treatments and to retain generally acceptable levels of alpha, beta, and power (1-beta); in this case, alpha = .05 for a two-tailed test and beta = .20 so that power = .80. For the purpose of illustration, sample size and ESs will be considered for the different comparisons in relation to the posttreatment evaluation of outcome.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">In the present survey, the median ES for comparing two treatments was .47 at posttreatment, with a range from .26 to .66 representing the 25th and 75th percentiles. <a href="#fig2">Figure 2</a> conveys the corresponding sample sizes needed for these ESs. A sample size of 71 per group would be needed to retain power at the desired level for the median ES, with a corresponding range from 232 to 36 subjects for the 25th and 75th percentiles.<a id="b-fn11"> </a><sup><a href="#fn11" /></sup>
Examination of the figure shows the number of subjects per group actually used. The median number of subjects for studies comparing alternative treatments was 12.0, with a range from 10 to 19 for the 25th and 75th percentiles. These actual sample sizes are far below the number needed to detect treatment differences.<br /><br /><a id="fig2"> </a><span class="centered"><img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/e0021437b009bf17ba2eac02e51cde7d/571c2fef/pdh/ccp/ccp-57-1-138-fig2a.gif" alt="ccp-57-1-138-fig2a.gif" title="Figure 2. Sample sizes required for comparisons of treatment (T) with another treatment or with no treatment (NT) separately for posttreatment (P) and follow-up (FU). (The sample sizes required are based on alpha = .05 for a two-tailed test, with power set at. 80 and an assumption of equal ns  per group. The column for each comparison reflects the range of sample sizes from the 25th and 75th percentiles; the horizontal line within each column corresponds to the median sample size needed. The upper figure represents the sample sizes required for power = .80 given the effect sizes that are obtained for the different types of comparisons; the lower figure conveys the actual sample sizes used in studies of the present survey.)" /><em>Figure 2. Sample sizes required for comparisons of treatment (T) with another treatment or with no treatment (NT) separately for posttreatment (P) and follow-up (FU). (The sample sizes required are based on alpha = .05 for a two-tailed test, with power set at. 80 and an assumption of equal ns  per group. The column for each comparison reflects the range of sample sizes from the 25th and 75th percentiles; the horizontal line within each column corresponds to the median sample size needed. The upper figure represents the sample sizes required for power = .80 given the effect sizes that are obtained for the different types of comparisons; the lower figure conveys the actual sample sizes used in studies of the present survey.)</em></span></p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">If the investigator wishes to compare treatment versus no treatment, the median ES is .78 at posttreatment. This ES is bounded by ESs of .54 and 1.05, which reflect the 25th and 75th percentiles and represent 50% of the studies surveyed. <a href="#fig2">Figure 2</a> plots the corresponding sample sizes for these ESs. A sample size of 27 per group would be needed for the desired power with the median ES for this comparison; the corresponding range of 54 to 14 subjects per group would be required for the 25th and 75th percentiles. These numbers are larger but closer to the actual sample sizes used. <a href="#fig2">Figure 2</a> shows the actual sample sizes, with a median of 12 at posttreatment bounded by a range from 10 to 18 for the respective percentiles.</p><a id="ccp-57-1-138-ID0EACAA" xmlns:Translation="urn:EBSCO-Translation"> </a><span class="medium-bold" xmlns:Translation="urn:EBSCO-Translation"><a data-auto="ep_link" href="#toc" id="hd_toc_65" title="Discussion">Discussion</a></span><br xmlns:Translation="urn:EBSCO-Translation" /><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Psychotherapy outcome research was examined in nine journals over a 3-year period (1984–86) to assess the extent to which studies are sufficiently powerful to detect differences between alternative treatment and control conditions. Effect sizes were estimated at posttreatment and follow-up, and these were used along with sample size data to evaluate power. The results can be discussed with reference to <a href="#c9">Cohen’s (1977)</a> criteria for small (.20), medium (.50), and large (.80) effect sizes. The present results indicate that comparisons of alternative treatments yield effect sizes close to the medium level (mean ESs = .50 at posttreatment and .47 at follow-up) and that comparisons of treatment versus no treatment tend to yield relatively large effect sizes (mean ESs = .85 at posttreatment and .89 at follow-up).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The question of interest is: To what extent are psychotherapy outcome studies sufficiently powerful to detect differences given these effect sizes? Using estimated effect sizes and sample sizes from the studies themselves and adopting an alpha of .05 (for two-tailed tests), we obtained power estimates. In evaluating the findings, we considered power ≥ .80 a criterion of adequate sensitivity of a test.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Power for comparisons of alternative treatments was below the recommended level (medians = .74 for posttreatment and .63 for follow-up). Indeed, for studies comparing two or more active treatments, fewer than half at posttreatment and fewer than one third at follow-up (45.3% and 28.6% of the studies) had power at or above the recommended level. The power to detect differences for comparisons of treatment versus no treatment was quite adequate (medians = .995 for both posttreatment and follow-up). Also, the majority of studies (82.5% and 90.0%) comparing treatment with a no-treatment control met or surpassed the power of. 80 at posttreatment and follow-up.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">A number of implications can be drawn from the present survey. First, power in psychotherapy outcome studies research is generally low for detecting small and medium effects. The need for improved power remains, and several recommendations made over 20 years ago (<a href="#c7">Cohen, 1965</a>) continue to be timely. The concern with weak power in relation to psychotherapy research echoes points voiced in relation to research in clinical, social, educational, and applied psychology more generally (e.g., <a href="#c1">Brewer, 1972</a>; <a href="#c4">Chase &amp; Chase, 1976</a>; <a href="#c6">Cohen, 1962</a>; <a href="#c43">Rossi et al., 1984</a>). Psychological research, of course, is not alone on this score. The absence of differences in major clinical trials of alternative interventions in medicine and public health may, in many instances, be attributed to insufficient power (see <a href="#c18">Freiman et al., 1978</a>).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">A second and more focused implication of the present results pertains to the special issues regarding comparative psychotherapy outcome research (<a href="#c22">Heimberg &amp; Becker, 1984</a>; <a href="#c25">Kazdin, 1986</a>). In evaluations of alternative psychotherapy techniques, both in individual studies and in literature reviews, a frequent interpretation is that there are few or no outcome differences between alternative techniques. Perhaps most treatment techniques are not very different in the effects they produce, and the common processes of therapy advanced to explain the null-hypothesis findings are well-based. However, in light of the present findings, it is appropriate and parsimonious to raise another prospect. Possibly, studies that compare alternative treatments are not sufficiently powerful to detect differences between treatments unless the effect sizes are large.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Given the complexities of clinical problems and psychotherapy and the limitations and variability of outcome assessment, large effects, even if they are evident in the population, might be difficult to obtain in a given investigation. The present survey suggests that effect sizes for comparisons of alternative treatments are likely to be in the small-to-medium range. Given the usual sample sizes that are used, the majority of studies may not be sufficiently powerful to detect such differences.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">There are several limitations of the present survey. To begin with, the methods of estimating and evaluating effect sizes in psychotherapy research are not entirely free from controversy. Significant issues such as the appropriate weighting of alternative outcome measures, the appropriate standard deviation unit, the extent to which the sample effect sizes within and among different studies can be pooled to estimate population effect sizes, the nonindependence of effect sizes computed for a given study for the types of comparisons of interest, and the exclusion of unpublished studies, (among others) have been carefully discussed, but not entirely resolved, in other secondary analyses. The present method of computing effect sizes followed several practices used in prior meta-analyses and is subject to similar issues and concerns. The present survey suffers from greater interpretive obstacles by combining studies, effect sizes, and power estimates across broad classes of treatment in which the identity of the type of treatment, patient, measure, and other study characteristics were ignored. The impact of these and other characteristics of therapy on effect sizes have been studied in large-scale meta-analyses (e.g., <a href="#c45">Shapiro &amp; Shapiro, 1982</a>; <a href="#c47">Smith et al., 1980</a>).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The purpose of the present survey was to examine broad classes of comparisons to estimate power. The estimates, when viewed in the range of 25th and 75th percentiles, provide an interval that suggests reasonable consistency, even though the distinctions between different techniques and studies were not made. One might want to examine whether the power of studies of particular treatments is weaker than that of others and to make technique distinctions. However, this was beyond the present goal.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">A feature directly related to different characteristics of the therapy studies was neglected in the present survey and may have important implications for power. The present analysis focused on the power to detect differences between treatments. The analyses examined main effects of a single variable (treatment technique). This focus is tantamount to asking the question, does psychotherapy work? The question has long been rejected as much too general to warrant serious attention (e.g., <a href="#c12">Edwards &amp; Cronbach, 1952</a>). The global question has been replaced by a more specific focus aimed at identifying which type of treatment works best for which type of client, as administered by which type of therapist under which circumstances (<a href="#c29">Kiesler, 1966</a>; <a href="#c39">Paul, 1967</a>). This question focuses on interactions (e.g., Treatment × Patient × Therapist × Setting) rather than simply on the efficacy of treatment or the relative effectiveness of different treatments. Yet, testing interactions in factorial studies is likely to divide samples into smaller groups than those used to test main effects of treatment. If power is weak for testing the main effect of treatment techniques, a fortiori, it is likely to be weak for testing the interactions. This concern has been voiced in relation to other areas of psychological research in which the inadequacy of power to test statistical interactions is common (<a href="#c5">Chase &amp; Tucker, 1975</a>; <a href="#c7">Cohen, 1965</a>).</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Another limitation of the present evaluation is the exclusive focus on power and the limited discussion even within this domain. The focus has suggested that power needs to be increased in psychotherapy outcome studies given the magnitude of effect sizes usually reported. The discussion has emphasized that power is a function of alpha, sample size, and effect size. Sample size seems to be the only variable for the investigator to manipulate and improve given that the adherence to alpha (at .05 or .01) has become a strongly entrenched convention (<a href="#c9">Cohen, 1977</a>) and that effect size, at first blush, seems merely to reflect the state of affairs evident in nature, that is, an estimate of true population differences.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Actually, power entails much more than the factors emphasized in this article. Power is a function of effect size, which is influenced in manifold ways by the care and consistency with which an investigation is conducted. Stated generally, effect size can be increased or rather optimized in an investigation by reducing error variance. Methodological features such as selecting homogeneous sets of patients, ensuring the integrity of treatment, standardizing the assessment conditions, carefully choosing outcome measures, and similar practices increase the power of an investigation by reducing variability in its execution. Although the present focus was limited to consideration of power, power itself can be augmented by the careful execution of the study.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The present survey illustrates the utility of power analyses in evaluating the results of previously conducted research. Such analyses can estimate the likelihood that research can detect differences given sample and effect sizes. Another and more important use of power analysis is the planning of a study to ensure that sample sizes can detect an effect of a given magnitude (<a href="#c9">Cohen, 1977</a>; <a href="#c32">Kraemer &amp; Thiemann, 1987</a>; <a href="#c37">Meinert, 1986</a>). Psychotherapy outcome research can profit greatly from this use of power analyses. The usual impediment for incorporating power in the design of research is hesitancy in estimating effect size. However, data from meta-analyses of psychotherapy (<a href="#c2">Brown, 1987</a>) as well as descriptive analyses such as those found in the present survey provide estimates of the approximate effect sizes for alternative types of comparisons. As guidelines, they may be used to identify the sample sizes required for adequate power.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">It is possible, of course, that large sample sizes needed to provide adequate comparisons of treatment are not available for particular clinical problems or settings. These limitations do not necessarily warrant undertaking a comparison that has minimal chances of detecting differences. The levels of confidence adopted to protect against Type I error (alpha) and Type II error (beta) and the resulting power (1-beta) may need to be reconsidered. Depending on the specific question, the comparison of interest, and the cost and consequences of no differences between treatments, one might wish to vary alpha or beta (<a href="#c37">Meinert, 1986</a>), The issue requires consideration in advance of the execution of the study. Given the sample sizes usually used in comparative outcome studies and the likely effect sizes usually reported, differences are not likely to be detected with acceptable levels of power.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The neglect of power can have major implications for interpreting research, perhaps especially so in the evaluation of psychotherapy. As noted previously, psychotherapy research is an area in which the absence of differences is often taken to be quite significant from conceptual and clinical perspectives. It may well be that treatments are similar in the outcomes they produce and that findings of no difference reflect the actual state of the population. However, there remains a plausible alternative hypothesis. The present evaluation suggests that the power of studies comparing alternative treatments is relatively weak. The results are not intended to fuel further the search for the superiority of one treatment over another. More sophisticated questions involving interactions of treatment with variables or other conditions of interest need to be studied. However, the points raised in relation to power in the present survey may need to be considered even further. Unless sample sizes are substantially increased from current levels, finer grained analyses of treatments are likely to be associated with even lower power as the division of the sample for the comparisons of interest results in smaller units for analyses.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">The present survey evaluated alternative classes of comparisons that are made in comparative outcome studies. The implications of weak power for more specific substantive questions (e.g., Treatment × Patient × Therapist × Setting interactions) were not addressed. Even so, the general conclusion that might be drawn is worth underscoring. The absence of differences between treatments in comparative outcome studies may not be interpreted unambiguously without improved power. In the context of psychotherapy research, as opposed to government and politics, it may be the absence rather than the presence of power that corrupts.</p><a id="ccp-57-1-138-ID0EAA" xmlns:Translation="urn:EBSCO-Translation"> </a><span class="medium-bold" xmlns:Translation="urn:EBSCO-Translation"><a data-auto="ep_link" href="#toc" id="hd_toc_82" title="Footnotes">Footnotes</a></span><a id="fn1" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn1">1</a></sup> <em>Power</em> (1-beta) is the probability of rejecting the null hypothesis when it is false. Stated differently, power is the likelihood of finding differences between the treatments when, in fact, the treatments are truly different in their outcomes.</p><a id="fn2" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn2">2</a></sup> The level of power that is adequate is not easily specified or justified mathematically. As with the level of confidence (alpha), the decision is based on convention about the margin of protection one should have against falsely accepting the null hypothesis (beta). <a href="#c7">Cohen (1965)</a> recommended adoption of the convention that beta = .20 and hence power (1-beta) = .80 when alpha = .05. This translates to the 4 in 5 likelihood of detecting an effect when a difference exists in the population. Although power ≥ .80 is used as a criterion for discussion in the present article, a higher level (.90, .95) is often encouraged as the acceptable criterion (e.g., <a href="#c18">Freiman, Chalmers, Smith, &amp; Kuebler, 1978</a>; <a href="#c19">Friedman, Furbere, &amp; DeMets, 1985</a>).</p><a id="fn3" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn3">3</a></sup> A list of the studies for the present analyses is available on request.</p><a id="fn4" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn4">4</a></sup> In meta-analyses of psychotherapy, effect sizes obtained by comparing treatment versus alternative types of control groups are occasionally no different (<a href="#c3">Casey &amp; Berman, 1985</a>). For the present purposes, the distinction between no-treatment (including waiting-list) control and attention-placebo control was nevertheless retained. The rationale was the likelihood that effect size and power would be tower for detecting differences between treatment and an attention-placebo group than between treatment and a no-treatment group. The differences could have important implications for designing studies if sample sizes need to be planned in accord with different expected effect sizes. Also, evaluations of alternative treatments have occasionally noted that a strong placebo is often no more or less effective than a technique considered to be more well-grounded in theory, research, or practice (<a href="#c27">Kazadin &amp; Wilcoxon, 1976</a>; <a href="#c40">Prioleau, Murdock, &amp; Brody, 1983</a>). Thus, no-treatment and active control conditions reflect different substantive issues.</p><a id="fn5" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn5">5</a></sup> In computing effect sizes, not all researchers have used the pooled standard deviation as the estimate of variance. The pooled estimate was used in the present analyses because it is readily estimated from studies in which <em>t</em> and <em>F</em> tests are reported but standard deviations for individual groups are omitted. In addition, the pooled estimate may be a less-biased estimate than the standard deviation of the control group (<a href="#c21">Hedges &amp; Olkin, 1985</a>).</p><a id="fn6" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn6">6</a></sup> Within a given study, more than one outcome measure was likely to be included. In some previous meta-analyses, separate outcome measures have been used as separate ESs for the data analyses. The issues raised with this procedure include the undue weight given to studies with a large number of outcome measures and the nonindependence of observations (ESs) for any data analyses. An alternative strategy is to calculate a mean ES for a given comparison (e.g., treatment vs. non-treatment) by averaging the ESs from the individual outcome measures. Thus, for a given study with a treatment and no-treatment control condition, one ES would be generated for that comparison based on the mean of ESs for all of the outcome measures. Alternative strategies for handling multiple outcomes within a study have different limitations. A major limitation of the present method is that it assumes that all outcome measures in a study should be weighted equally (i.e., are equally important). There remains no consensus on how to prioritize outcome measures to resolve this concern (see <a href="#c2">Brown, 1987</a>).</p><a id="fn7" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn7">7</a></sup> In meta-analyses, comparisons of treatment versus control groups do not use absolute effect size. In such analyses, the interest is in identifying positive or negative effect sizes, that is, in whether the treatment group was better or worse than the control group. Effect size data based on directional differences of treatment versus control conditions for the present survey are available from the authors.</p><a id="fn8" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn8">8</a></sup> This figure is an underestimate of follow-up evaluations of psychotherapy studies because investigators occasionally publish follow-up data in publications separate from the original article in which posttreatment data were presented.</p><a id="fn9" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn9">9</a></sup> The magnitudes for small, medium, and large effect sizes have been revised from those specified originally by <a href="#c6">Cohen (1962)</a>, which were .25, .50, and 1.00. The effect sizes of .20, .50, and .80 reflect the magnitudes in more recent references (<a href="#c9">Cohen, 1977</a>).</p><a id="fn10" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn10">10</a></sup> Because of the small number of studies, the data for this comparison will not be discussed further. However, estimates of ES, power, and related information are presented in the tables.</p><a id="fn11" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><sup><a href="#b-fn11">11</a></sup> The requisite sample (<em>N</em>) or group (<em>n</em>) sizes for a given alpha, power, and effect size of various increments can be obtained from various published tables (see <a href="#c9">Cohen, 1977</a>; <a href="#c23">Hinkle &amp; Oliver, 1983</a>; <a href="#c32">Kraemer &amp; Thiemann, 1987</a>). For the present purposes, the requisite group sizes, when we assumed an equal number per group, were obtained by direct calculation (see <a href="#c33">Lachin, 1981</a>; <a href="#c48">Snedecor &amp; Cochran, 1980</a>). For a two-tailed test of means from two independent samples of equal group sizes,
<a id="eq1"> </a><span class="centered"><img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/f5e40f9c6a10836289c9d675a5fab676/571c2fef/pdh/ccp/ccp-57-1-138-eq1a.gif" alt="ccp-57-1-138-eq1a.gif" title=" " /><em> </em></span>
For a two-tailed test with alpha = .05 and beta = .20, this translates to
<a id="eq2"> </a><span class="centered"><img class="rs_skip" src="http://largecontent.ebsco-content.com/embimages/492455f896cec626ba35a5f9aeed9395/571c2fef/pdh/ccp/ccp-57-1-138-eq2a.gif" alt="ccp-57-1-138-eq2a.gif" title=" " /><em> </em></span>
.</p><a id="ccp-57-1-138-ID0E0VB0ABAA" xmlns:Translation="urn:EBSCO-Translation"> </a><span class="medium-bold" xmlns:Translation="urn:EBSCO-Translation"><a data-auto="ep_link" href="#toc" id="hd_toc_106" title="References">References</a></span><a id="c1" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Brewer, J. K. (1972). On the power of statistical tests in the <em>American Educational Research Journal</em>. <em>American Educational Research Journal</em>, <em>9</em>, 391–401.</p><a id="c2" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Brown, J. (1987). A review of meta-analyses conducted on psychotherapy outcome research. <em>Clinical psychology review</em>, <em>7</em>, 1–23.</p><a id="c3" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Casey, R. J., &amp; Berman, J. S. (1985). The outcome of psychotherapy with children. <em>Psychological Bulletin</em>, <em>98</em>, 388–400.</p><a id="c4" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Chase, L. J., &amp; Chase, R. B. (1976). A statistical power analysis of applied psychological research. <em>Journal of Applied Psychology</em>, <em>61</em>, 234–237.</p><a id="c5" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Chase, L. J., &amp; Tucker, R. K. (1975). A power-analytic examination of contemporary communication research. <em>Speech Monographs</em>, <em>42</em>, 29–41.</p><a id="c6" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Cohen, J. (1962). The statistical power of abnormal-social psychological research: A review. <em>Journal of Abnormal and Social Psychology</em>, <em>65</em>, 145–153.</p><a id="c7" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Cohen, J. (1965). Some statistical issues in psychological research. In B. B.Wolman (Ed.), <em>Handbook of clinical psychology</em> (pp. 95–121). New York: McGraw-Hill.</p><a id="c8" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Cohen, J. (1973). Statistical power analysis and research results. <em>American Education Research Journal</em>, <em>10</em>, 225–230.</p><a id="c9" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Cohen, J. (1977). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). New York: Academic Press.</p><a id="c10" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Cross, D. G., Sheehan, P. W., &amp; Khan, J. A. (1982). Short- and long-term follow-up of clients receiving insight-oriented therapy and behavior therapy. <em>Journal of Consulting and Clinical Psychology</em>, <em>50</em>, 103–112.</p><a id="c11" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">DiLoreto, A. O. (1971). <em>Comparative psychotherapy: An experimental analysis</em>. Chicago: Aldine-Atherton.</p><a id="c12" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Edwards, A. L., &amp; Cronbach, L. J. (1952). Experimental design for research in psychotherapy. <em>Journal of Clinical Psychology</em>, <em>8</em>, 51–59.</p><a id="c13" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Fagley, N. S. (1985). Applied statistical power analysis and the interpretation of nonsignificant results by research consumers. <em>Journal of Counseling Psychology</em>, <em>32</em>, 391–396.</p><a id="c14" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Feldman, R. A., Caplinger, T. E., &amp; Wodarski, J. S. (1983). <em>The St. Louis conundrum: The effective treatment of antisocial youths</em>. Englewood Cliffs, NJ: Prentice-Hall.</p><a id="c15" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Fleischman, M. J. (1981). A replication of Patterson’s “Intervention for boys with conduct problems.”<em>Journal of Consulting and Clinical Psychology</em>, <em>49</em>, 342–351.</p><a id="c16" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Forman, S. G. (1980). A comparison of cognitive training and response cost procedures of modifying aggressive behavior of elementary school children. <em>Behavior Therapy</em>, <em>11</em>, 594–600.</p><a id="c17" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Frank, J. D. (1982). Therapeutic components shared by all psychotherapies. In J. H.Harvey &amp; M. M.Parks (Eds.), <em>Psychotherapy research and behavior change</em> (<em>Vol. 1</em>, pp. 5–37). Washington, DC: American Psychological Association.</p><a id="c18" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Freiman, J. A., Chalmers, T. C., Smith, H., &amp; Kuebler, R. R. (1978). The importance of beta, the Type II error, and sample size in the design and interpretation of the randomized control trial. <em>New England Journal of Medicine</em>, <em>299</em>, 690–694.</p><a id="c19" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Friedman, L. M., Furberg, C. D., &amp; DeMets, D. L. (1985). <em>Fundamentals of clinical trials</em> (2nd ed.). Littleton, MA: PSG Publications.</p><a id="c20" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Garfield, S. L. (1980). <em>Psychotherapy: An eclectic approach</em>. New York: Wiley.</p><a id="c21" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Hedges, L. V., &amp; Olkin, I. (1985). <em>Statistical methods format-analysis</em>. Orlando. FL: Academic Press.</p><a id="c22" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Heimberg, R. G., &amp; Becker, R. E. (1984). Comparative outcome research. In M.Hersen, L.Michelson, &amp; A. S.Bellack (Eds.), <em>Issues in psychotherapy research</em> (pp. 251–283). New York: Plenum Press.</p><a id="c23" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Hinkle, D. E., &amp; Oliver, J. D. (1983). How large should the sample be? A question with no simple answer? Or. …<em>Educational and Psychological Measurement</em>, <em>43</em>, 1051–1060.</p><a id="c24" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Kazdin, A. E. (1980). <em>Research design in clinical psychology</em>. New York: Harper &amp; Row.</p><a id="c25" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Kazdin, A. E. (1986). Comparative outcome studies of psychotherapy: Methodological issues and strategies. <em>Journal of Consulting and Clinical Psychology</em>, <em>54</em>, 95–105.</p><a id="c26" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Kazdin, A. E. (1988). <em>Child psychotherapy: Developing and identifying effective treatments</em>. New York: Pergamon Press.</p><a id="c27" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Kazdin, A. E., &amp; Wilcoxon, L. A. (1976). Systematic desensitization and nonspecific treatment effects: A methodological evaluation. <em>Psychological Bulletin</em>, <em>83</em>, 729–758.</p><a id="c28" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Kazdin, A. E., &amp; Wilson, G. T. (1978). <em>Evaluation of behavior therapy: Issues, evidence, and research strategies</em>. Cambridge, MA: Ballinger.</p><a id="c29" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Kiesler, D. J. (1966). Some myths of psychotherapy research and the search fora paradigm. <em>Psychological Bulletin</em>, <em>65</em>, 110–136.</p><a id="c30" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Klein, M. H., Dittmann, A. T., Parloff, M. B., &amp; Gill, M. M. (1969). Behavior therapy: Observations and reflections. <em>Journal of Consulting and Clinical Psychology</em>, <em>33</em>, 259–266.</p><a id="c31" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Kraemer, H. C. (1981). Coping strategies in psychiatric clinical research. <em>Journal of Consulting and Clinical Psychology</em>, <em>49</em>, 309–319.</p><a id="c32" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Kraemer, H. C., &amp; Thiemann, S. (1987). <em>How many subjects? Statistical power analysis in research</em>. Newbury Park, CA: Sage.</p><a id="c33" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Lachin, J. M. (1981). Introduction to sample size determination and power analysis for clinical trials. <em>Controlled Clinical Trials</em>, <em>2</em>, 93–113.</p><a id="c34" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Lambert, M. J., Shapiro, D. A., &amp; Bergin, A. E. (1986). The effectiveness of psychotherapy. In S. L.Garfield &amp; A. E.Bergin (Eds.), <em>Hand-book of psychotherapy and behavior change</em> (3rd ed., (pp. 157–211). New York: Wiley.</p><a id="c35" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Liberman, R. P., &amp; Eckman, T. (1981). Behavior therapy vs. insight-oriented therapy for repeated suicide attemptors. <em>Archives of General Psychiatry</em>, <em>38</em>, 1126–1130.</p><a id="c36" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Luborsky, L., Singer, B., &amp; Luborsky, L. (1975). Comparative studies of psychotherapies: Is it true that “everyone has won and all must have prizes?”<em>Archives of General Psychiatry</em>, <em>32</em>, 995–1008.</p><a id="c37" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Meinert, C. L. (1986). <em>Clinical trials: Design, conduct, and analysis</em>. New York: Oxford University Press.</p><a id="c38" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Patterson, G. R. (1974). Interventions for boys with conduct problems: Multiple settings, treatments, and criteria. <em>Journal of Consulting and Clinical Psychology</em>, <em>42</em>, 471–481.</p><a id="c39" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Paul, G. L. (1967). Outcome research in psychotherapy. <em>Journal of Consulting Psychology</em>, <em>31</em>, 109–118.</p><a id="c40" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Prioleau, L., Murdock, M., &amp; Brody, N. (1983). An analysis of psychotherapy versus placebo studies. <em>The Behavioral and Brain Sciences</em>, <em>8</em>, 275–285.</p><a id="c41" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Rachman, S. J., &amp; Wilson, G. T. (1980). <em>The effects of psychological therapy</em> (2nd ed.). Oxford, England: Pergamon Press.</p><a id="c42" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Rosenthal, R. (1979). The “file drawer problem” and tolerance for null results. <em>Psychological Bulletin</em>, <em>86</em>, 638–641.</p><a id="c43" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Rossi, J. S., Rossi, S. R., &amp; Cottrill, S. D. (1984, April). <em>Statistical power of research in social and abnormal psychology: What have we gained in 20 years?</em> Paper presented at the meeting of the Eastern Psychological Association, Baltimore, MD.</p><a id="c44" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Rush, A. J., Beck, A. T., Kovacs, M., &amp; Hollon, S. (1977). Comparative efficacy of cognitive therapy and pharmacotherapy in the treatment of depressed outpatients. <em>Cognitive Therapy and Research</em>, <em>1</em>, 17–38.</p><a id="c45" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Shapiro, D. A., &amp; Shapiro, D. (1982). Meta-analysis of comparative therapy outcome studies: A replication and refinement. <em>Psychological Bulletin</em>, <em>92</em>, 581–604.</p><a id="c46" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Sloane, R. B., Staples, F. R., Cristol, A. H., Yorkston, N. J., &amp; Whipple, K. (1975). <em>Psychotherapy versus behavior therapy</em>. Cambridge, MA: Harvard University Press.</p><a id="c47" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Smith, M. L., Glass, G. V., &amp; Miller, T. I. (1980). <em>The benefits of psychotherapy</em>. Baltimore, MD: Johns Hopkins University Press.</p><a id="c48" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Snedecor, G. W., &amp; Cochran, W. G. (1980). <em>Statistical methods</em> (7th ed.). Ames: Iowa State University Press.</p><a id="c49" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Stiles, W. B., Shapiro, D. A., &amp; Elliott, R. (1986). “Are all psychotherapies equivalent?”<em>American Psychologist</em>, <em>41</em>, 165–180.</p><a id="c50" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Viale-Val, G., Rosenthal, R. H., Curtiss, G., &amp; Marohn, R. C. (1984). Dropout from adolescent psychotherapy: A preliminary study. <em>Journal of the American Academy of Child Psychiatry</em>, <em>23</em>, 562–568.</p><a id="c51" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Walrond-Skinner, S. (1986). <em>Dictionary of psychotherapy</em>. London: Routledge &amp; Kegan Paul.</p><a id="c52" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Waterhouse, G. J., &amp; Strupp, H. H. (1984). The patient-therapist relationship: Research from the psychodynamic perspective. <em>Clinical Psychology Review</em>, <em>4</em>, 77–92.</p><a id="c53" xmlns:Translation="urn:EBSCO-Translation"> </a><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation">Yu, P., Harris, G. E., Solovitz, B. L., &amp; Franklin, J. L. (1986). A social problem-solving intervention for children at high risk for later psychopathology. <em>Journal of Clinical Child Psychology</em>, <em>15</em>, 30–40.</p><p class="body-paragraph" data-auto="body_paragraph" xmlns:Translation="urn:EBSCO-Translation"><em>Submitted: </em>February 1, 1988<em> Revised: </em>May 10, 1988<em> Accepted: </em>May 23, 1988</p><hr noshade="noshade" /><p class="body-paragraph" data-auto="copyright_info">This publication is protected by US and international copyright laws and its content may not be copied without the copyright holders express written permission except for the print or download capabilities of the retrieval software used for access. This content is intended solely for the use of the individual user.<br xmlns:ExtendedMarkupController="urn:ExtendedMarkupController" /><br xmlns:ExtendedMarkupController="urn:ExtendedMarkupController" /><strong xmlns:ExtendedMarkupController="urn:ExtendedMarkupController">Source:&nbsp;</strong>Journal of Consulting and Clinical Psychology. Vol. 57. (1), Feb, 1989 pp. 138-147)<br xmlns:ExtendedMarkupController="urn:ExtendedMarkupController" /><strong xmlns:ExtendedMarkupController="urn:ExtendedMarkupController">Accession Number:&nbsp;</strong>1989-26789-001<br xmlns:ExtendedMarkupController="urn:ExtendedMarkupController" /><strong xmlns:ExtendedMarkupController="urn:ExtendedMarkupController">Digital Object Identifier:&nbsp;</strong>10.1037/0022-006X.57.1.138</p></section></div>
		

		<div class="widget-loading loading"></div>
	
		<!-- WorldCat Widgets-->
		

	<!-- Full text will be rendered in this placeholder if citation is being displayed with
	full text. -->
	
	
	

	<div class="content-footer" >
	 

	</div>
	
	<div class="rs-placeholder" id="ctl00_ctl00_MainContentArea_MainContentArea_speaker_box" style="display:none;" data-parent="textToSpeechPlaceholder" data-readid="TextToSpeech" data-speed="MEDIUM" data-voice="ScanSoft_Jill_Full_22kHz" data-server="http://app.rs.ebscohost.com/cgi-bin/rsent?customerid=5845" data-download="true" data-isdetail="true"> </div>



						</div>
					</div>
					<div id="column1" class="collapsible" >
	<a class="collapsible-toggle" href="#" ></a>
	<div class="collapsible-content">
		
	


<h3 class="vis-hidden">View:</h3>
<ul class="format-control" >
		<li id="ctl00_ctl00_Column1_Column1_formatButtonsTop_formatButtonRepeater_ctl01_listItem" class="format-item">
			 
			<!-- Making assumption that we don't want spaces between MARC link and parenthesis. -->
			
			
			<a id="ctl00_ctl00_Column1_Column1_formatButtonsTop_formatButtonRepeater_ctl01_linkButton" title="Detailed Record" class="record-type format-citation" href="javascript:__doPostBack(&#39;ctl00$ctl00$Column1$Column1$formatButtonsTop$formatButtonRepeater$ctl01$linkButton&#39;,&#39;&#39;)">Detailed Record</a>
			
			
			
		</li>
	
		<li id="ctl00_ctl00_Column1_Column1_formatButtonsTop_formatButtonRepeater_ctl02_listItem" class="format-item active">
			 
			<!-- Making assumption that we don't want spaces between MARC link and parenthesis. -->
			
			
			
			<span id="ctl00_ctl00_Column1_Column1_formatButtonsTop_formatButtonRepeater_ctl02_label" title="HTML Full Text" class="record-type html-ftwg">HTML Full Text</span>
			
			
		</li>
	
		<li id="ctl00_ctl00_Column1_Column1_formatButtonsTop_formatButtonRepeater_ctl03_listItem" class="format-item">
			 
			<!-- Making assumption that we don't want spaces between MARC link and parenthesis. -->
			
			<span id="ctl00_ctl00_Column1_Column1_formatButtonsTop_formatButtonRepeater_ctl03_hddnInstructionMessage" class="hidden">This PDF document opens in a frame, to view the document outside of a frame, please change your Adobe Reader settings. To do this, open Adobe Reader, go to Help Menu and select Accessibility Setup Assistant option then select Use Recommend Settings and Skip Setup. You only need to do this once with the current computer you are using.</span>
			<a id="ctl00_ctl00_Column1_Column1_formatButtonsTop_formatButtonRepeater_ctl03_linkButton" title="PDF Full Text" class="record-type pdf-ft" href="javascript:__doPostBack(&#39;ctl00$ctl00$Column1$Column1$formatButtonsTop$formatButtonRepeater$ctl03$linkButton&#39;,&#39;&#39;)">PDF Full Text</a>
			
			
			<span id="ctl00_ctl00_Column1_Column1_formatButtonsTop_formatButtonRepeater_ctl03_suffix" class="format-note">(983.6KB)</span>
		</li>
	</ul>
	

	
	<div id="citedExternalSources"  style="display:none;">
		
	</div>
	
		<h3 class="hidden">Cited References</h3>
		<ul class="reference-links" >
	
		<li >
			<span id="ctl00_ctl00_Column1_Column1_referencebuttoncontrol_referenceButtonRepeater_ctl01_ReferenceLinkContainer">				
				<a id="ctl00_ctl00_Column1_Column1_referencebuttoncontrol_referenceButtonRepeater_ctl01_ReferenceLinkCitation" class="marc-link" href="javascript:__doPostBack(&#39;ctl00$ctl00$Column1$Column1$referencebuttoncontrol$referenceButtonRepeater$ctl01$ReferenceLinkCitation&#39;,&#39;&#39;)">Times Cited in this Database</a>				
				<a id="ctl00_ctl00_Column1_Column1_referencebuttoncontrol_referenceButtonRepeater_ctl01_ReferenceLink" class="marc-link" href="javascript:__doPostBack(&#39;ctl00$ctl00$Column1$Column1$referencebuttoncontrol$referenceButtonRepeater$ctl01$ReferenceLink&#39;,&#39;&#39;)">(51)</a>				
			</span>			
			
		</li>
	</ul>

	
	
	
	
	</div>
</div>
					<div role="complementary" id="column2" class="collapsible" >
	<a class="collapsible-toggle" href="#" ></a>
	<div class="collapsible-content" >
		
	<hr class="vis-none" />
<h2 title="Tools" accesskey="5" tabindex="0" class="article-tools-header" id="ArticleTools"  >Tools</h2>
<ul class="article-tools delivery-control" >
		<li class="article-tool" >
			<a   href="#" title="Print" class="print-link"    data-panel='{"Id":"print","Url":"delivery/printpanel","Js":"ep/controller/control/citationdeliverypanel.js"}' >Print</a>
		</li>
		<li class="article-tool" >
			<a   href="#" title="E-mail" class="email-link"    data-panel='{"Id":"email","Url":"delivery/emailpanel","Js":"ep/controller/control/citationdeliverypanel.js"}' >E-mail</a>
		</li>
		<li class="article-tool" >
			<a   href="#" title="Save" class="save-link"    data-panel='{"Id":"save","Url":"delivery/savepanel","Js":"ep/controller/control/citationdeliverypanel.js"}' >Save</a>
		</li>
		<li class="article-tool" >
			<a   href="#" title="Cite" class="cite-link"    data-panel='{"Id":"cite","Url":"delivery/citepanel","Js":"ep/controller/control/citepanel.js"}' >Cite</a>
		</li>
		<li class="article-tool" >
			<a   href="#" title="Export" class="export-link"    data-panel='{"Id":"export","Url":"/ehost/delivery/exportpanel?sid=491cf965-6fb3-4046-b6ad-482934299d76@sessionmgr4001\u0026vid=0\u0026form=False","Js":"ep/controller/control/exportpanel.js"}' >Export</a>
		</li>
		<li class="article-tool" >
			<a   href="#" title="Permalink" class="permalink-link"    data-panel='{"Id":"permalink","Url":"delivery/permalinkpanel","Js":"ep/controller/control/plinkpanel.js"}' >Permalink</a>
		</li>
		<li class="article-tool" >
			<a   href="#" title="Share" class="bookmark-link"    data-panel='{"Id":"bookmark","Url":"addthis/addthispanel","Js":"ep/controller/control/bookmarkpanel.js"}' >Share</a>
		</li>

</ul>

	</div>
</div>
				
					
				
				<div class="extra1" role="presentation">&nbsp;</div>
			</div>
			<div class="footer-wrapper" >
				
	

				<div class="push-sticky-footer"></div>
			</div>
		</div>
		
	

				
		


	</form>
	
</body>
</html>
